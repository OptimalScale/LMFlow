{
"model_name_or_path": "huggyllama/llama-7b",
"dataset_path": "./preprocessed/translations_oscar_json",
"output_dir": "./output_models/llama7b_bilingual",
"num_train_epochs": 1,
"learning_rate": 1e-5,
"block_size": 2048,
"per_device_train_batch_size": 4,
"gradient_accumulation_steps": 1,
"gradient_checkpointing": 1,
"deepspeed": "configs/ds_config_zero3.json",
"fp16": true,
"group_texts_batch_size": 2048,
"save_total_limit": 20,
"run_name": "llama7b_bilingual",
"logging_steps": 1,
"do_train": true,
"ddp_timeout": 72000,
"save_steps": 500,
"dataloader_num_workers": 1,
"report_to": "wandb",
"lr_scheduler_type": "constant",
"tf32": 1
}
