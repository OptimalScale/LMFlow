# general
## model
model_name_or_path: meta-llama/Meta-Llama-3-8B-Instruct
reference_model_name_or_path: meta-llama/Meta-Llama-3-8B-Instruct
reward_model_name_or_path: sfairXC/FsfairX-LLaMA3-RM-v0.1
trust_remote_code: True

## data
dataset_path_list:
  - data/iterative-prompt-3it/iter1
  - data/iterative-prompt-3it/iter2
  - data/iterative-prompt-3it/iter3
conversation_template: llama3
preprocessing_num_workers: 16

## pipeline
output_dir: ./output_models/iterative_dpo
run_name: iterative_dpo
random_seed: 42
use_accelerator: True
enable_distributed_inference: True
distributed_inference_num_instances: 8
initial_iter_idx: 0 # 0 refers to the first dataset in dataset_path_list
do_response_generation: True
do_scoring: True
do_dpo_align: True


# inference phase
## general
apply_chat_template: True
num_output_sequences: 8
use_beam_search: False
temperature: 1.0
top_p: 1.0
max_new_tokens: 2048
enable_decode_inference_result: True

## vllm
use_vllm: True
vllm_gpu_memory_utilization: 0.95
vllm_tensor_parallel_size: 1
vllm_inference_batch_size: 16


# reward model scoring phase
reward_arch_type: text_regression
reward_torch_dtype: bf16
reward_use_flash_attention: True
reward_model_inference_block_size: 2048
overwrite_cache: True
reward_model_inference_batch_size: 10 # the actual batch size for rm forward will be reward_model_inference_batch_size * num_output_sequences


# dpo phase
## model
do_train: True
use_flash_attention: True

## data
sampling_paired_method: max_min
margin_scale: 1.0
length_penalty: 0
max_prompt_length: 1000
mask_prompt: False

## pipeline
### training
accelerate_config_file: configs/accelerate_dsz2_config.yaml
bf16: True
num_train_epochs: 2
max_steps: 1200
learning_rate: 5.0e-7
warmup_steps: 100
per_device_train_batch_size: 1
per_device_eval_batch_size: 1
gradient_accumulation_steps: 16
gradient_checkpointing: True
loss_type: sigmoid
lr_scheduler_type: cosine
optim: paged_adamw_32bit

### logging
logging_steps: 2
save_strategy: steps
save_steps: 500
evaluation_strategy: steps
eval_steps: 500
report_to: wandb