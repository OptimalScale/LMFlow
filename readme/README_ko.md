<p align="center" width="100%">
<img src="../assets/logo.png" alt="LMFlow" style="width: 100%; min-width: 300px; display: block; margin: auto; background-color: transparent;">
</p>

# LMFlow

<h4 align="center">
    <p>
        <a href="https://github.com/OptimalScale/LMFlow/blob/main/README.md">English</a> |
        <a href="https://github.com/OptimalScale/LMFlow/blob/main/readme/README_zh-hans.md">η®€δ½“δΈ­ζ–‡</a> |
        <a href="https://github.com/OptimalScale/LMFlow/blob/main/readme/README_es.md">EspaΓ±ol</a> |
        <a href="https://github.com/OptimalScale/LMFlow/blob/main/readme/README_jp.md">ζ—¥ζ¬θ</a> |
        <b>ν•κµ­μ–΄</b> |
        <a href="https://github.com/OptimalScale/LMFlow/blob/main/readme/README_hindi.md">ΰ¤Ήΰ¤Ώΰ¤‚ΰ¤¦ΰ¥€</a>
    <p>
</h4>


[![Code License](https://img.shields.io/badge/Code%20License-Apache_2.0-green.svg)](https://github.com/OptimalScale/LMFlow/blob/main/LICENSE)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/release/python-390/)
[![Doc](https://img.shields.io/badge/Website-Doc-ff69b4.svg)](https://optimalscale.github.io/LMFlow/)
[![Embark](https://img.shields.io/badge/discord-LMFlow-%237289da.svg?logo=discord)](https://discord.gg/u9VJNpzhvA)
[![slack badge](https://img.shields.io/badge/Slack-join-blueviolet?logo=slack&amp)](https://join.slack.com/t/lmflow/shared_invite/zt-1wju9nicy-woXbNtS~5MavHSAtiMxmxQ)
[![WeChat badge](https://img.shields.io/badge/WeChat-Join-brightgreen?logo=wechat&amp)](https://i.328888.xyz/2023/04/04/ibvpAk.jpeg)

LMFlowλ” Large Machine Learning Modelμ νμΈνλ‹μ„ μ„ν•΄ ν™•μ¥κ°€λ¥ν• νΈλ¦¬ν•κ³  ν¨μ¨μ μΈ ν΄μ…λ‹λ‹¤. λΉ λ¥΄κ³ , μ μ € μΉν™”μ μ΄κ³ , λ¨λ‘κ°€ μ‹ λΆ°ν•  μ μλ„λ΅ μ„¤κ³„λμ—μµλ‹λ‹¤.

LMflowμ λΉ„μ „μ„ [vision](https://github.com/OptimalScale/LMFlow#vision) ν™•μΈν•΄μ£Όμ„Έμ”.

<p align="center" width="100%">
<img src="../assets/features.png" alt="LMFlow-features" style="width: 100%; min-width: 300px; display: block; margin: auto;">
</p>


## Latest News
* [2023-04-02] [Web service is online!](https://lmflow.com/)
* [2023-04-01] [Release Chinese checkpoints in model zoo: LLaMA-7B-tuned, LLaMA-13B-tuned, LLaMA-33B-tuned.](https://github.com/OptimalScale/LMFlow#model-zoo)
* [2023-04-01] [Release English checkpoints in model zoo: LLaMA-7B-medical, LLaMA-13B-medical, and LLaMA-33B-medical.](https://github.com/OptimalScale/LMFlow#model-zoo)
* [2023-03-27] [Support full tuning and lora tuning for all decoder models.](https://github.com/OptimalScale/LMFlow#supported-models)
* [2023-03-27] [Tasked tuned model beats ChatGPT on medical domain](https://github.com/OptimalScale/LMFlow#model-performance)
* [2023-03-27] [Release code and checkpoints - version 0.0.1](https://optimalscale.github.io/LMFlow/)


## Demos

### ν„μ¬ μ²΄ν¬ν¬μΈνΈ λ‹¤μ΄λ΅λ“ μ„λΉ„μ¤ capacityλ¥Ό μ΄κ³Όν•΄μ„ μ„λΉ„μ¤ capacityλ¥Ό λλ¦¬κΈ° μ„ν•΄ ν•λ‚μ μ„λ²„λ¥Ό μ¶”κ°€λ΅ ν• λ‹Ήν–μµλ‹λ‹¤. 
"_too many HTTP requests_"λΌλ” μ—λ¬κ°€ λ°μƒν•λ‹¤λ©΄ λ‡ λ¶„ μ •λ„ κΈ°λ‹¤λ Έλ‹¤κ°€ λ‹¤μ‹ μ‹λ„ν•΄μ£ΌκΈ° λ°”λλ‹λ‹¤.

LMflowλ” λ‹¤μκ³Ό κ°™μ€ λ„¤ κ°μ λ°λ¨λ¥Ό μ κ³µν•©λ‹λ‹¤.
- μ¨λΌμΈ μ„λΉ„μ¤: μ½”λ“μ‹¤ν–‰ μ—†μ΄ μ €ν¬μ λ¨λΈμ„ μ‹¤ν–‰ν•΄λ³΄μ‹κ³  μ‹¶μΌμ‹  λ¶„λ“¤μ„ μ„ν•΄μ„ instruction-tuned LLaMA-7Bμ™€ LLaMA-33B λ°°ν¬ν•μ€μµλ‹λ‹¤.
- μ½”λ© μ±—λ΄‡ (shell): μ‰ κΈ°λ°μ μƒνΈμ‘μ© μ±—λ΄‡μΌλ΅ μ½”λ©μ—μ„ μ±—λ΄‡μ„ μ‰½κ² λ°°ν¬ν•΄λ³΄μ‹¤ μ μμµλ‹λ‹¤.
- μ½”λ© μ±—λ΄‡ (web): μ›Ή κΈ°λ°μ μƒνΈμ‘μ© μ±—λ΄‡μΌλ΅ μ½”λ©μ—μ„ μμ‹ λ§μ μ±—λ΄‡μ„ μ‰½κ² λ°°ν¬ν•΄λ³΄μ‹¤ μ μμµλ‹λ‹¤.
- λ΅μ»¬ λ°°ν¬: λ΅μ»¬μ—μ„ λ¨λΈ/μ±—λ΄‡μ„ λ°°ν¬ν•  μ μλ” λ°©λ²• λν• μ κ³µν•κΈ° λ•λ¬Έμ— μ¶©λ¶„ν• λ¦¬μ†μ¤κ°€ μμΌμ‹λ‹¤λ©΄ μ„μ μ„Έ κ°€μ§€ λ°©λ²•λ³΄λ‹¤ ν›¨μ”¬ ν° λ¨λΈμ„ λ°°ν¬ν•΄λ³΄μ‹¤ μ μμµλ‹λ‹¤.


[![Code License](https://img.shields.io/badge/Online%20Service-Web-green.svg)](https://lmflow.com)
[![colab badge](https://img.shields.io/badge/Colab-(shell)%20%20chatbot:%20gpt--neo-orange?logo=google-colab&amp)](https://colab.research.google.com/drive/1P9Hf6_mLE7WHH92pw73j9D5kz6GTdkow?usp=sharing)
[![colab badge](https://img.shields.io/badge/Colab-(web)%20%20chatbot:%20gpt--neo-blue?logo=google-colab&amp)](https://colab.research.google.com/drive/1LLtiiQO-ZIIFsTKxYzGWYX9BDRc-v8dq?usp=sharing)


### Online Service
> LMflowμ [μ›Ή μ„λΉ„μ¤λ¥Ό](https://lmflow.com/) λ°©λ¬Έν•΄μ£Όμ‹λ©΄ κ°μ‚¬ν•κ² μµλ‹λ‹¤. LMflowμ μ›Ήμ‚¬μ΄νΈμ— LLaMA-7B-tunedμ™€ LLaMA-33B-tunedλ¥Ό λ―Έλ¦¬ λ°°ν¬ν•΄ λ†“μ•μµλ‹λ‹¤.  μ›Ήμ‚¬μ΄νΈ νΈλν”½μ΄ λ§μ„ κ²½μ°, μ›Ήμ‚¬μ΄νΈκ°€ μ μ ν•κ² μ‘λ‹µν•μ§€ μ•μ„ μ μμ§€λ§, μ›Ή μ„λΉ„μ¤μ `Local Deploy`λ¥Ό μ°Έμ΅°ν•μ—¬ μ§μ ‘ λ°°ν¬ν•΄λ³΄μ‹¤ μλ„ μμµλ‹λ‹¤.

### Colab chatbot(shell)
<p align="center" width="100%">
<img src="../assets/colab-shell-chatbot-demo.png">
</p>

LMflowλ” κµ¬κΈ€ μ½”λ©μ T4/P100/V100 GPUλ¥Ό μ΄μ©ν• κ°„λ‹¨ν• μ‰ μ±—λ΄‡ λ°λ¨λ¥Ό μ κ³µν•©λ‹λ‹¤. λ°λ¨λ΅ μ κ³µλλ” `gpt-neo-2.7b` λ¨λΈμ€ μμ–΄λ΅λ§ μ‚¬μ©ν•μ‹¤ μ μκ³ , λ‹¤λ¥Έ LLM λ¨λΈμ— λΉ„ν•΄ μ„±λ¥μ΄ λ›°μ–΄λ‚μ§€ μ•μ€ λ°λ¨μ© λ¨λΈμ„μΌλ΅ μ°Έκ³ λ§ ν•΄μ£Όμ‹λ©΄ κ°μ‚¬ν•κ² μµλ‹λ‹¤. μ μ €λ” LMFlowμ„ ν†µν•΄ μμ‹ μ λ°μ΄ν„°μ…‹μ— λ¨λΈμ„ νμΈνλ‹ν•κ³  λ” λ‚μ€ μ„±λ¥μ„ μ–»μ„ μ μμµλ‹λ‹¤. λν•, π¤—[huggingface](https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads)μ—μ„ μ κ³µν•λ” λ‹¤λ¥Έ decoder-only λ¨λΈλ“¤ λν• λ‹¤μκ³Ό κ°™μ΄ νμΈνλ‹ ν•΄λ³΄μ‹¤ μ μμµλ‹λ‹¤.

```sh
./scripts/run_chatbot.sh {another-model-name}
```




### Colab chatbot(web)
LMflowλ” κµ¬κΈ€ μ½”λ©μ T4/P100/V100 GPUλ¥Ό μ΄μ©ν• κ°„λ‹¨ν• μ›Ή λ°λ¨ μ±—λ΄‡μ„ μ κ³µν•©λ‹λ‹¤. λ°λ¨λ΅ μ κ³µλλ” `gpt-neo-2.7b` λ¨λΈμ€ μμ–΄λ΅λ§ μ‚¬μ©ν•μ‹¤ μ μκ³ , λ‹¤λ¥Έ LLM λ¨λΈμ— λΉ„ν•΄ μ„±λ¥μ΄ λ›°μ–΄λ‚μ§€ μ•μ€ λ°λ¨μ© λ¨λΈμ„μΌλ΅ μ°Έκ³ λ§ ν•΄μ£Όμ‹λ©΄ κ°μ‚¬ν•κ² μµλ‹λ‹¤.

### Local Deploy
μ¶©λ¶„ν• λ΅μ»¬ λ¦¬μ†μ¤κ°€ μκ³ , λ¨λΈμ„ λ΅μ»¬μ—μ„ λ°°ν¬ν•κ³  μ‹¶μ–΄ν•λ” μ μ €λ¥Ό μ„ν•΄, LMflowλ” λ°±μ—”λ“(λ‹¤λ¥Έ ν”„λ΅ νΈμ—”λ“μ— μ„λΉ„μ¤λ¥Ό μ κ³µν•κΈ° μ„ν•΄)μ™€ interactive μ›Ή ν”„λ΅ νΈμ—”λ“(μ§μ ‘ λ€ν™”ν•  μ μκ² ν•΄μ£Όλ”)μ launchλ¥Ό μ„ν• ν”λΌμ¤ν¬ μ„λ²„λ¥Ό μ‰½κ² μ‹¤ν–‰ν•  μ μλ” λ°©λ²•μ„ μ κ³µν•©λ‹λ‹¤. 
```sh
cd ./service
python app.py
```

## Medical Performance
|                |  PubMedQA (ID) | MedQA-USMLE (OOD) | MedMCQA (ID) |  Average |
|:---------:|:--------:|:-----------:|:-------:|:----:|
| Human (pass)   |  60.0   |     50.0    |         |      |
| Human (expert) |    78.0   |     87.0    |  90.0   | 85.0 |
|   |      |              |    |  |
|  InstructGPT 175B   |   73.2   |     46.0    |  44.0   | 54.4 |
|    ChatGPT |    63.9   |     **57.0**    |  44.7   | 55.2 |
|      LLaMA 7B   |    5.2   |     27.1    |  24.3   | 18.9 |
|      LLaMA 33B |    1.8   |     43.4    |  30.3   | 25.2 |
|   |      |             |            |    |  |
|   Task-tuned LLaMA 7B (Full) |   **75.1**   |     44.5    |  49.9   | 56.5 |
| Task-tuned LLaMA 33B (LoRA) |  74.0  |  51.3   | **50.2**|**58.5**|


LLaMA 33B (LoRA)μ μ„±λ¥μ€ λ‹¨μΌ 8 \* A100 μ„λ²„λ΅ PubMedQAμ™€ MedMCQAμ„ μ‚¬μ©ν•μ—¬, 16μ‹κ°„λ™μ• νμΈνλ‹ν• κ²°κ³Όμ…λ‹λ‹¤. Instruction tuning λ“±μ„ ν¬ν•¨ν•΄ λ” λ§μ€ λ¨λΈ μ„±λ¥μ— λ€ν•΄μ„ μ•κ³  μ‹¶μΌμ‹λ©΄, λ‹¤μ [λ¬Έμ„](https://optimalscale.github.io/LMFlow/)λ¥Ό μ°Έμ΅°ν•΄μ£Όμ„Έμ”.

## Model Zoo
LMflowλ” ν•™μµλ μ²΄ν¬ν¬μΈνΈλ“¤μ„ ν†µν•΄ μ¶”κ°€ ν•™μµ λ° μ¶”λ΅ ν•μ‹¤ μ μλ„λ΅ λ¨λ“  λ¨λΈμ„ μ¤ν”μ†μ¤λ΅ μ κ³µν•©λ‹λ‹¤.

| Instruct-tuned Models   |  Status | Base Model | Download |
|----------|:-------------:|----------|:-------------:|
| LLaMA-7B-tuned | ![completed](https://geps.dev/progress/100) | LLaMA-7B | [Google Drive](https://drive.google.com/file/d/1x5JLae3akVkfFeDhSe3TEyUbPn_GNFyb/view?usp=share_link) |
| LLaMA-13B-tuned | ![completed](https://geps.dev/progress/100) | LLaMA-13B |  [Google Drive](https://drive.google.com/file/d/1m_rpe6rNpN59kWvjJ3GfKeEmS-68TRYr/view?usp=share_link) |
| LLaMA-33B-tuned | ![completed](https://geps.dev/progress/100) |LLaMA-33B |  [Google Drive](https://drive.google.com/file/d/1IqgqLHwNkWQ7BffheZnqD6a-8Zul1bk6/view?usp=share_link) |
| LLaMA-65B-tuned | ![training](https://geps.dev/progress/65) | LLaMA-65B | Google Drive |
| LLaMA7B-medical | ![completed](https://geps.dev/progress/100) | LLaMA-7B | [Google Drive](https://drive.google.com/file/d/1Z44tsrRvfDFvucbNGFjHC_vbPcBvg3x-/view?usp=share_link) |
| LLaMA13B-medical | ![completed](https://geps.dev/progress/100) | LLaMA-13B |  [Google Drive](https://drive.google.com/file/d/1uoTAXTMyYQkP6N4ummx7tj-c4v1p91ap/view?usp=share_link) |
| LLaMA33B-medical | ![completed](https://geps.dev/progress/100) |LLaMA-33B |  [Google Drive](https://drive.google.com/file/d/14N9o_1pwHmVuSikQ3orMVzZDrLYJC0iM/view?usp=share_link) |
| LLaMA65B-medical | ![training](https://geps.dev/progress/90) | LLaMA-65B | Google Drive |


## Supported Pipelines

| Pipelines   |   Status |
|----------|:-------------:|
| Task Tuning |  :white_check_mark: Supported |
| Instruction Tuning |  :white_check_mark: Supported |
| Parameter-Efficient Tuning |  :white_check_mark: Supported |
| Large Model Inference |  :white_check_mark: Supported |
| Alignment Tuning |  :wrench: Developing |



## Supported Models

π¤— huggingfaceμ λ¨λ“  [λ””μ½”λ” λ¨λΈ](https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads)μ— LMflowλ¥Ό μ›ν™ν•κ² μ μ©ν•΄λ³΄μ‹¤ μ μμµλ‹λ‹¤. LLaMA, GPT2, GPT-Neo, Galactica λ“±μ€ μ™„λ²½ν•κ² ν…μ¤νΈ μ™„λ£λμ—μµλ‹λ‹¤. μ¶”ν›„ LMflowλ” μΈμ½”λ” λ¨λΈλ„ μ§€μ›ν•  μμ •μ…λ‹λ‹¤.


## 1.Setup

μ†ν”„νΈμ›¨μ–΄ ν¨ν‚¤μ§€λ” Linux μ΄μ μ²΄μ (Ubuntu 20.04)μ—μ„ μ™„λ²½ν•κ² ν…μ¤νΈλμ—μµλ‹λ‹¤. λ‹¤λ¥Έ μ΄μ μ²΄μ  ν”λ«νΌ(MacOS, Windows)μ€ ν…μ¤νΈλ¥Ό μ§„ν–‰ν•κ³  μμΌλ―€λ΅ μμƒμΉ λ»ν• μ¤λ¥κ°€ λ°μƒν•  μ μμµλ‹λ‹¤. Linux μ‹μ¤ν…μ—μ„ μ‚¬μ©ν•μ‹λ” κ²ƒμ„ μ¶”μ²λ“λ¦¬κ³ , Google Colabμ„ ν†µν•΄ ν…μ¤νΈν•΄λ³΄μ‹κΈ° λ°”λλ‹λ‹¤.

```bash
git clone https://github.com/OptimalScale/LMFlow.git
cd LMFlow
conda create -n lmflow python=3.9 -y
conda activate lmflow
conda install mpi4py
pip install -e .
```

## 2.Prepare Dataset
λ‹¤μμ„ μ‹¤ν–‰ν•λ©΄ μμ  ν•™μµ λ°μ΄ν„°μ…‹κ³Ό ν…μ¤νΈ λ°μ΄ν„°μ…‹μ„ μ‰½κ² λ‹¤μ΄λ΅λ“ν•μ‹¤ μ μμµλ‹λ‹¤.
```bash
cd data
bash download.sh all
cd -
```

λ‹¤μ ν•μ‹μΌλ΅ κ°„λ‹¨ν λ³€ν™ν•λ©΄ μμ‹ μ λ°μ΄ν„°μ…‹μ„ λ¨λΈν•™μµμ— μ‚¬μ©ν•  μ μμµλ‹λ‹¤.
```json
{
  "type": "text2text",
  "instances": [
    {
      "input": "Question: The Transformer architecture [START_REF]",
      "output": "N/A"
    },
    ...
  ]
}
```
```json
{
  "type": "text_only",
  "instances": [
    {
      "text": "Defintion: In this task, we ask you to write an answer to a question that involves events that may be stationary (not changing over time) or transient (changing over time). For example, the sentence \"he was born in the U.S.\" contains a stationary event since it will last forever; however, \"he is hungry\" contains a transient event since it will remain true for a short period of time. Note that a lot of the questions could have more than one correct answer. We only need a single most-likely answer. Please try to keep your \"answer\" as simple as possible. Concise and simple \"answer\" is preferred over those complex and verbose ones. \n Input: Question: Sentence: It's hail crackled across the comm, and Tara spun to retake her seat at the helm. \nQuestion: Will the hail storm ever end? \n Output: NA \n\n"
    },
    ...
  ]
}
```
## 3. Run Scripts
### 3.1 Run νμΈνλ‹

`scripts/run_finetune.sh` λ¥Ό μ‹¤ν–‰ν•μ—¬ GPT-2 λ² μ΄μ¤ λ¨λΈμ„ νμΈνλ‹ν•  μ μμµλ‹λ‹¤.
```sh
./scripts/run_finetune.sh
```

deepspeedμ— argumentsλ¥Ό μ¶”κ°€λ΅ μ…λ ¥ν•μ‹κ³ μ ν•  κ²½μ°,
```sh
./scripts/run_finetune.sh "--num_gpus=8 --master_port 10001"
```

LoRA νμΈνλ‹μ„ ν™μ„±ν•μ‹κ³ μ ν•  κ²½μ°,
```sh
./scripts/run_finetune_with_lora.sh
```



μμ„Έν• μ„¤μ •μ€ μ΄ μ¤ν¬λ¦½νΈλ“¤μ„ μ§μ ‘ μμ •ν•  μ μμµλ‹λ‹¤. μ΄ μ¤ν¬λ¦½νΈλ“¤μ€ μ‹¤μ λ΅λ” νμ΄μ¬ μ¤ν¬λ¦½νΈ `examples/finetune.py`λ¥Ό νΈμ¶ν•λ©°, λ‹¤μκ³Ό κ°™μ΄ μ‚¬μ©ν•μ‹¤ μ μμµλ‹λ‹¤.

```sh
deepspeed ${deepspeed_args} \
  examples/finetune.py \
    --deepspeed configs/ds_config_zero3.json \
    --bf16 \
    --run_name finetune_with_lora \
    --model_name_or_path facebook/galactica-1.3b \
    --num_train_epochs 0.01 \
    --learning_rate 2e-5 \
    --dataset_path ${dataset_path} \
    --per_device_train_batch_size 1 \
    --per_device_eval_batch_size 1 \
    --validation_split_percentage 0 \
    --logging_steps 20 \
    --block_size 512 \
    --do_train \
    --output_dir output_models/finetune \
    --overwrite_output_dir \
    --ddp_timeout 72000 \
    --save_steps 5000 \
    --dataloader_num_workers 1
```
μ—¬κΈ°μ„λ” `--num_train_epochs`μ epoch μλ¥Ό `0.01` λ΅ μ„¤μ •ν•μ—¬ νμΈνλ‹ ν”„λ΅μ„Έμ¤λ¥Ό λΉ λ¥΄κ² μ™„λ£ν•  μ μμµλ‹λ‹¤. λ” λ‚μ€ μ„±λ¥μ λ¨λΈμ„ μ–»κ³  μ‹¶λ‹¤λ©΄ ν•μ΄νΌνλΌλ―Έν„°λ¥Ό μ΅°μ •ν•μ‹λ©΄ λ©λ‹λ‹¤. 


λ¨λ“  κ°€λ¥ν• νμΈνλ‹ argumentsλ¥Ό ν™•μΈν•μ‹λ ¤λ©΄,
```python
python examples/finetune.py -h
```

μ°Έκ³ λ΅ ν›λ ¨ λ°μ΄ν„° μ„ΈνΈκ°€ μ‘μ€ κ²½μ° ``block_size`` μ κ°’μ„ λ‚®μ¶°μ•Όλ§ ν•©λ‹λ‹¤. κ·Έλ ‡μ§€ μ•μΌλ©΄ Epoch Iterationμ—μ„ μƒν”μ„ μ‚¬μ©ν•  μ μ—†κ²λ©λ‹λ‹¤.

νμΈνλ‹ λ λ¨λΈ μ²΄ν¬ν¬μΈνΈλ” μ„μ μμ‹μ—μ„ `--output_dir`λ΅ μ§€μ •λ μΈμμ— μ €μ¥λ©λ‹λ‹¤. 
μ΄ κ²½μ°μ—λ”`output_models/finetune` μ…λ‹λ‹¤.

### 3.2 Run Evaluation

κΈ°μ΅΄ huggingface λ¨λΈλ΅ μ§μ ‘ Evaluationμ„ μ‹¤ν–‰ν•  μ μμµλ‹λ‹¤.

μλ¥Ό λ“¤μ–΄ GPT2 largeλ¥Ό μ‹¤ν–‰ν•λ ¤λ©΄, λ‹¤μμ„ μ‰ μ¤ν¬λ¦½νΈλ¥Ό μ‚¬μ©ν•μ‹κ±°λ‚
```sh
./scripts/run_evaluation.sh
```
λ‹¤μ λ…λ Ήμ–΄λ¥Ό ν†µν•΄ νμ΄μ¬ μ¤ν¬λ¦½νΈλ¥Ό μ‹¤ν–‰ν•μ‹­μ‹μ¤.
```python
CUDA_VISIBLE_DEVICES=0 \
    deepspeed examples/evaluate.py \
    --answer_type medmcqa \
    --model_name_or_path gpt2-large \
    --dataset_path data/MedQA-USMLE/validation \
    --deepspeed examples/ds_config.json
```
νμΈνλ‹ λ λ¨λΈμ„ λ΅λ“ν•λ ¤λ©΄ μ €μ¥λ λ¨λΈ μ²΄ν¬ν¬μΈνΈ λ””λ ‰ν† λ¦¬ κ²½λ΅λ¥Ό `--model_name_or_path`λ¥Ό μ‚¬μ©ν•΄ μ§€μ •ν•μ‹­μ‹μ¤.

LoRA νμΈνλ‹ λ λ¨λΈμ κ²½μ° λ‹¤μμ„ μ°Έμ΅°ν•μ‹­μ‹μ¤.
```sh
./scripts/run_evaluation_with_lora.sh
```

μ΄λ¬ν• μ¤ν¬λ¦½νΈλ” μ €ν¬μ APIλ¥Ό κΈ°λ°μΌλ΅ κµ¬μ¶•λ μμ  `examples/*.py` λ¥Ό νΈμ¶ν•©λ‹λ‹¤. 
λ” λ§μ€ API κ΄€λ ¨ μμ λ” unittestμ `tests` λ©”μ†λ“λ¥Ό μ°Έμ΅°ν•μ‹­μ‹μ¤.

## 4. Additional Notes
### 4.1 LLaMA Checkpoint

1. λ¨Όμ € [facebookresearch/llama](https://github.com/facebookresearch/llama)μ—μ„ LLaMA λ¨λΈμ— λ€ν• μ•΅μ„Έμ¤ κ¶ν•μ„ μ–»μ–΄μ•Όν•©λ‹λ‹¤. κ³µμ‹ μ²΄ν¬ν¬μΈνΈλ¥Ό λ‹¤μ΄λ΅λ“ν•κ³  κ²½λ΅λ¥Ό `${llama-path}`μ— μ €μ¥ν•μ‹­μ‹μ¤.

2. μ•„λμ μ»¤λ§¨λ“λ¥Ό μ‹¤ν–‰ν•μ—¬ κ³µμ‹ μ²΄ν¬ν¬μΈνΈ `${llama-path}`λ¥Ό HuggingFaceκ°€ μ§€μ›ν•λ” μ²΄ν¬ν¬μΈνΈ `${llama-hf-path}`λ΅ λ³€ν™ν•μ‹­μ‹μ¤.

    `python ./scripts/convert_llama_weights_to_hf.py --input_dir ${llama-path} --model_size 7B --output_dir ${llama-hf-path}/llama-7b-hf`

3. κ·Έ λ‹¤μμ— `${llama-hf-path}/llama-7b-hf`λ΅ μ²΄ν¬ν¬μΈνΈ κ²½λ΅λ¥Ό μ„¤μ •ν•μ‹λ©΄ λμ…λ‹λ‹¤.

4. (μ„ νƒ μ‚¬ν•­) μ¤λ¦¬μ§€λ„ llama-7b-hf Pre-trained λ¨λΈ μ „λ¶€λ¥Ό λ‹¤μ΄λ΅λ“ν•μ‹κ³ μ ν•  κ²½μ° λ‹¤μμ„ μ‹¤ν–‰ν•μ„Έμ”.
```sh
cd output_models && ./download.sh all && cd -
```
`./scripts/run_evaluation_with_lora.sh`μ™€ μ μ‚¬ν• λ°©μ‹μΌλ΅ λ‹¤μμ„ μ‹¤ν–‰ν•μ—¬, νμΈνλ‹ν• λ¨λΈ differenceλ¥Ό μ–»μ„ μ μμµλ‹λ‹¤.
```sh
CUDA_VISIBLE_DEVICES=0 \
    deepspeed examples/evaluate.py \
    --answer_type text \
    --model_name_or_path ${llama-hf-path}/llama-7b-hf \
    --lora_model_path output_models/${llama-model-diff-path} \
    --dataset_path data/alpaca/test \
    --prompt_structure "Input: {input}" \
    --deepspeed examples/ds_config.json
```
μ΄μ  νμΈνλ‹λ llama λ¨λΈλ΅ ν‰κ°€ν•  μ μμµλ‹λ‹¤.

### 4.2 DeepSpeed Config
configλ” configsλ¥Ό ν†µν•΄ κµ¬μ„±ν•  μ μμµλ‹λ‹¤. μμ„Έν• λ‚΄μ©μ€ [DeepSpeed Configuration](https://www.deepspeed.ai/docs/config-json/)μ°Έμ΅°ν•μ‹­μ‹μ¤.

## 5. Model Release

### 5.1 Medical Model Checkpoints
λ‹¤μ μ¤ν¬λ¦½νΈλ¥Ό μ‹¤ν–‰ν•μ—¬ μ €ν¬μ μλ£ λ¨λΈ μ²΄ν¬ν¬μΈνΈλ¥Ό λ‹¤μ΄λ΅λ“ ν•μ‹¤ μ μμµλ‹λ‹¤.

```bash
cd output_models
bash download.sh medical_ckpt
cd -
```
λν• λ‹¤μ Google λ“λΌμ΄λΈ λ§ν¬λ¥Ό ν†µν•΄ μ§μ ‘ λ¨λΈμ„ λ‹¤μ΄λ΅λ“ ν•  μ μμµλ‹λ‹¤ : [medical_ckpt.tar.gz](https://drive.google.com/file/d/1bnsQGNGNYchsOfiNyRAmL2fNiowbmFNw/view?usp=share_link)

### 5.2 Instruction Model Checkpoints
λ‹¤μ μ¤ν¬λ¦½νΈλ¥Ό μ‹¤ν–‰ν•μ—¬ μ €ν¬μ instruction λ¨λΈ μ²΄ν¬ν¬μΈνΈλ¥Ό λ‹¤μ΄λ΅λ“ ν•μ‹¤ μ μμµλ‹λ‹¤.
```bash
cd output_models
bash download.sh instruction_ckpt
cd -
```

λ‹¤μ μ¤ν¬λ¦½νΈλ¥Ό μ‹¤ν–‰ν•μ—¬ μ €ν¬μ instruction λ¨λΈ μ²΄ν¬ν¬μΈνΈλ¥Ό λ‹¤μ΄λ΅λ“ ν•μ‹¤ μ μμµλ‹λ‹¤. [instruction_ckpt.tar.gz](https://drive.google.com/file/d/1d_ioQ-ViVweeifbsFSO4pczc3UORFHZO/view?usp=share_link)

### 5.3 Begin Reproduce

λ¨λΈ μ²΄ν¬ν¬μΈνΈλ¥Ό λ‹¤μ΄λ΅λ“ ν• ν›„μ—λ” `--lora_model_path` λ¥Ό `output_models/instruction_ckpt/llama7b-lora`(llama-7b for instructionμ μμ‹)λ΅ λ€μ²΄ν•κ³ , `--model_name_or_path` λ¥Ό `LMFlow/scripts/run_evaluation_with_lora.sh` λ‚΄λ¶€μ λ³€ν™ λ llama λ¨λΈλ΅ λ€μ²΄ ν• λ‹¤μ μ΄ μ…Έ μ¤ν¬λ¦½νΈλ¥Ό μ‹¤ν–‰ν•μ—¬ κ²°κ³Όλ¥Ό μ¬ν„ ν•  μ μμµλ‹λ‹¤.

κ·Έλ° λ‹¤μ [λ¬Έμ„](https://optimalscale.github.io/LMFlow/)μ—μ„ λ¨λΈ μ„±λ¥μ„ ν™•μΈν•μ‹¤ μ μμµλ‹λ‹¤.

## Documentation
λ” λ§μ€ API μ°Έμ΅° λ° μ‹¤ν— κ²°κ³Όλ” [Documentation](https://optimalscale.github.io/LMFlow/)λ¥Ό μ°Έμ΅°ν•μ‹­μ‹μ¤.

## Vision
μ•λ…•ν•μ„Έμ”! LMflowλ” μ™„μ „ν• LLM ν•™μµ ν”„λ΅μ„Έμ¤λ¥Ό ν¬ν•¨ν•μ—¬ μ‚¬μ©μκ°€ μμ‹ μ μ–Έμ–΄ λ¨λΈμ„ λΉ λ¥΄κ² κµ¬μ¶•ν•κ³  ν¨κ³Όμ μΌλ΅ ν•™μµ ν•  μ μλ„λ΅ν•λ” μ½”λ“ repositoryκ°€ κ³§ μ¶μ‹ λ  κ²ƒμ„ λ°ν‘ν•κ² λμ–΄ κΈ°μ©λ‹λ‹¤.

μ°λ¦¬μ μ½”λ“ repositoryλ” λ‹¨μν• λ¨λΈμ΄ μ•„λ‹λ©° μ™„μ „ν• ν•™μµ μ›ν¬ ν”λ΅, λ¨λΈ μµμ ν™” λ° ν…μ¤νΈ λ„κµ¬λ¥Ό ν¬ν•¨ν•©λ‹λ‹¤. λ€ν™” λ¨λΈ, μ§λ¬Έ/λ‹µλ³€ λ¨λΈ λ° κΈ°νƒ€ ν…μ¤νΈ μƒμ„± λ¨λΈμ„ λΉ„λ΅―ν• λ‹¤μ–‘ν• μ ν•μ μ–Έμ–΄ λ¨λΈμ„ κµ¬μ¶•ν•λ” λ° μ‚¬μ©ν•  μ μμµλ‹λ‹¤.

λν• LMflowλ” LLM κ³µμ  ν”λ«νΌμ„ λ§λ“¤μ–΄ μ‚¬λλ“¤μ΄ μ²΄ν¬ν¬μΈνΈμ™€ κ²½ν—μ„ κ³µμ ν•μ—¬ μ»¤λ®¤λ‹ν‹°μ κΈ°μ μ„ ν•¨κ» κ°μ„ ν•  μ μλ” κ°λ°©μ μ΄κ³  λ―Όμ£Όμ μΈ LLM κ³µμ  ν”λ«νΌμ„ λ§λ“¤κ³ μν•©λ‹λ‹¤. LLMμ— κ΄€μ‹¬μλ” λ„κµ¬λ‚ μ°Έμ—¬ν•μ—¬ μΉκ·Όν•κ³  κ°λ°©μ μΈ μ»¤λ®¤λ‹ν‹°λ¥Ό λ§λ“¤μ–΄ κ°€κ³ μ ν•©λ‹λ‹¤.

μ΄λ³΄μλ“  μ „λ¬Έκ°€λ“  μƒκ΄€μ—†μ΄ μ΄ ν”λ«νΌμ—μ„ λ§μ€ ννƒμ„ λ°›μ„ μ μμ„ κ²ƒμ΄λΌκ³  λ―Ώμµλ‹λ‹¤. ν•¨κ» ν™κΈ°μ°¨κ³  νμ‹ μ μΈ LLM μ»¤λ®¤λ‹ν‹°λ¥Ό λ§λ“¤μ–΄ λ΄…μ‹λ‹¤!

[![Embark](https://img.shields.io/badge/discord-LMFlow-%237289da.svg?logo=discord)](https://discord.gg/u9VJNpzhvA)
[![slack badge](https://img.shields.io/badge/Slack-join-blueviolet?logo=slack&amp)](https://join.slack.com/t/lmflow/shared_invite/zt-1wju9nicy-woXbNtS~5MavHSAtiMxmxQ)
[![WeChat badge](https://img.shields.io/badge/WeChat-Join-brightgreen?logo=wechat&amp)](https://i.328888.xyz/2023/04/04/ibvpAk.jpeg)

## Disclaimer

μ΄ ν¨ν‚¤μ§€λ” λ€ν• λ¨λΈ νλ‹μ„ μ„ν• κ°„μ†ν™” λ μ‚¬μ©μ μΉν™”μ μΈ νμ΄ν”„ λΌμΈμ„ μ κ³µν•λ” κ²ƒμ„ λ©ν‘λ΅ν•©λ‹λ‹¤. λ”°λΌμ„ μ–΄λ– ν• λ²•μ μΈ μ±…μ„λ„ μ§€μ§€ μ•μµλ‹λ‹¤.
κ·Έ κΈ°λ¥μ€ μ°Έμ΅° μ©λ„λ΅ μ κ³µλλ©° μ‚¬μ©μκ°€ μ‚¬μ©ν•λ„λ΅ μλ„λμ—μµλ‹λ‹¤. κ·Έλ¬λ‚ λ°μ΄ν„° λ° μ‚¬μ „ ν•™μµλ λ¨λΈκ³Ό κ΄€λ ¨λ μ±…μ„μ€ μ‚¬μ©μμ—κ² λ‹¬λ ¤μμµλ‹λ‹¤. μ΄ ν¨ν‚¤μ§€λ” μ‚¬μ©μ μ¤€λΉ„ κµ¬μ„± μ”μ†μ μ •ν™•μ„±, μ™„μ „μ„±, μ μ© κ°€λ¥μ„± λλ” λ²•μ  μ ν•©μ„±μ„ λ³΄μ¦ν•μ§€ μ•μµλ‹λ‹¤. μ‚¬μ©μλ” λ¨λΈ λ° λ°μ΄ν„°μ μ¤€λΉ„μ™€ κ΄€λ ¨λ λ¨λ“  μ„ν—κ³Ό μ±…μ„μ„ μΈμ‹ν•κ³  κ°€μ •ν•κ³  μ΄ ν¨ν‚¤μ§€λ¥Ό ν™μ©ν•κΈ° μ „μ— λ²•μ , μƒμ—…μ  λ° κΈ°μ μ  μλ¬Έμ„ λ°›μ•„μ•Όλ§ ν•©λ‹λ‹¤. νμ΄ν”„ λΌμΈμ€ μ‚¬μ©μμ μλ»λ λ°μ΄ν„° λ° μ‚¬μ „ ν•™μµ λ λ¨λΈμ μ¤€λΉ„λ΅ μΈν• μ–΄λ– ν• μ§μ ‘μ μΈ, κ°„μ ‘μ μΈ, νΉμ, λ¶€μμ  λλ” κ²°κ³Όμ  μ†ν•΄μ— λ€ν•΄μ„λ„ μ±…μ„μ„ μ§€μ§€ μ•μµλ‹λ‹¤.

μμ–΄μ™€ μ¤‘κµ­μ–΄ λ²„μ „ λ¨λ‘λ¥Ό ν¬ν•¨ν•λ” μ κ²€ ν¬μΈνΈλ” μ—°κµ¬ λ©μ μΌλ΅λ§ μ κ³µλ©λ‹λ‹¤. 
μ΄λ¬ν• μ²΄ν¬ ν¬μΈνΈμ— ν¬ν•¨ λ κµμ΅ λ°μ΄ν„°μ—λ” ChatGPT μ–Έμ–΄ λ¨λΈμ—μ„ μƒμ„± λ κ²°κ³Όκ°€ ν¬ν•¨λ©λ‹λ‹¤. μ΄λ¬ν• μ²΄ν¬ ν¬μΈνΈμ λ°°ν¬ λλ” μ‚¬μ©μ„ λ³΄μ¦ν•κ±°λ‚ μ¥λ ¤ν•μ§€ μ•μµλ‹λ‹¤. μ΄λ¬ν• μ²΄ν¬ ν¬μΈνΈμ μ‚¬μ©μλ” μ¬λ°”λ¥΄κ³  μ μ ν•κ² μ‚¬μ©λμ—λ”μ§€ ν™•μΈν•λ” κ²ƒμ€ μ „μ μΌλ΅ μ‚¬μ©μμ μ±…μ„μ…λ‹λ‹¤.

λν• λ¨λΈμ—μ„ μƒμ„± λ κ²°κ³Όλ” ν™•λ¥  λ¨λΈμ— κΈ°λ°ν•λ©° μ§μ ‘μ μΌλ΅ μ΄ νμ΄ν”„ λΌμΈκ³Ό κ΄€λ ¨μ΄ μ—†μμ„ κ°•μ΅°ν•λ” κ²ƒμ΄ μ¤‘μ”ν•©λ‹λ‹¤. κ²°κ³Όμ μ •ν™•μ„±, μ‹ λΆ°μ„±, μ μ© κ°€λ¥μ„± λ° λ²•μ  μ ν•©μ„±μ€ μ΄ νμ΄ν”„ λΌμΈμ—μ„ λ³΄μ¦λμ§€ μ•μµλ‹λ‹¤. λ”°λΌμ„ μ‚¬μ©μλ” κ²°κ³Όμ™€ κ΄€λ ¨λ μ„ν—κ³Ό μ±…μ„λ„ μΈμ‹ν•΄μ•Όν•λ©° λ¨λΈμ—μ„ μƒμ„± λ κ²°κ³Όμ— μμ΅΄ν•κΈ° μ „μ— λ²•μ , μƒμ—…μ  λ° κΈ°μ μ  μλ¬Έμ„ λ°›μ•„μ•Όν•©λ‹λ‹¤. νμ΄ν”„ λΌμΈμ€ μ‚¬μ©μκ°€ λ¨λΈμ—μ„ μƒμ„± ν• κ²°κ³Όμ— μμ΅΄ν•μ—¬ λ°μƒν•λ” μ–΄λ– ν• μ§μ ‘μ μΈ, κ°„μ ‘μ μΈ, νΉμ, λ¶€μμ  λλ” κ²°κ³Όμ  μ†ν•΄μ— λ€ν•΄μ„λ„ μ±…μ„μ§€μ§€ μ•μµλ‹λ‹¤.

## Support

λ„μ›€μ΄ ν•„μ”ν•λ©΄ κ³µμ‹ [κΉƒ ν—λΈ λ ν¬μ§€ν† λ¦¬](https://github.com/OptimalScale/LMFlow)μ— μ΄μλ¥Ό μƒμ„±ν•΄μ£Όμ„Έμ”.

## Contributors
<a href="https://github.com/OptimalScale/LMFlow/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=OptimalScale/LMFlow" />
</a>

## Citation
μ΄ repositoryλ¥Ό μ μ©ν•κ² μ‚¬μ©ν•μ…¨λ‹¤λ©΄ β­μ„ λλ¬μ£Όμ‹κ³  λ‹¤μμ„ ν†µν•΄ μΈμ©ν•΄μ£Όμ‹λ©΄ κ°μ‚¬ν•κ² μµλ‹λ‹¤.

```bibtex
@misc{lmflow,
  author = {Shizhe Diao and Rui Pan and Hanze Dong and KaShun Shum and Jipeng Zhang and Wei Xiong and Tong Zhang},
  title = {LMFlow: An Extensible Toolkit for Finetuning and Inference of Large Foundation Models},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://optimalscale.github.io/LMFlow/}},
}
```
