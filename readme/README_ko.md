<p align="center" width="100%">
<img src="../assets/logo.png" alt="LMFlow" style="width: 100%; min-width: 300px; display: block; margin: auto; background-color: transparent;">
</p>

# LMFlow

<h4 align="center">
    <p>
        <a href="https://github.com/OptimalScale/LMFlow/blob/main/README.md">English</a> |
        <a href="https://github.com/OptimalScale/LMFlow/blob/main/readme/README_zh-hans.md">ç®€ä½“ä¸­æ–‡</a> |
        <a href="https://github.com/OptimalScale/LMFlow/blob/main/readme/README_es.md">EspaÃ±ol</a> |
        <a href="https://github.com/OptimalScale/LMFlow/blob/main/readme/README_jp.md">æ—¥æœ¬èª</a> |
        <b>í•œêµ­ì–´</b> |
        <a href="https://github.com/OptimalScale/LMFlow/blob/main/readme/README_hindi.md">à¤¹à¤¿à¤‚à¤¦à¥€</a>
    <p>
</h4>

í•œêµ­ì–´ ë²„ì „ì€ ChatGPTê°€ ë²ˆì—­í–ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ìˆìœ¼ë©´ contributorê°€ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤. ë˜í•œ, ì˜ì–´ ë²„ì „ê³¼ ë‚´ìš©ì´ ë‹¤ë¥¸ ë¶€ë¶„ì´ ìˆìœ¼ë©´ ì˜ì–´ ë²„ì „ì„ ë”°ë¥´ì‹­ì‹œì˜¤.

[![Code License](https://img.shields.io/badge/Code%20License-Apache_2.0-green.svg)](https://github.com/OptimalScale/LMFlow/blob/main/LICENSE)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/release/python-390/)
[![Doc](https://img.shields.io/badge/Website-Doc-ff69b4.svg)](https://optimalscale.github.io/LMFlow/)
[![Embark](https://img.shields.io/badge/discord-LMFlow-%237289da.svg?logo=discord)](https://discord.gg/srGxyazbNs)
[![slack badge](https://img.shields.io/badge/Slack-join-blueviolet?logo=slack&amp)](https://join.slack.com/t/lmflow/shared_invite/zt-1s6egx12s-THlwHuCjF6~JGKmx7JoJPA)
[![WeChat badge](https://img.shields.io/badge/WeChat-Join-brightgreen?logo=wechat&amp)](https://i.328888.xyz/2023/04/04/ibvpAk.jpeg)

LMFlowëŠ” í° ë¨¸ì‹  ëŸ¬ë‹ ëª¨ë¸ì˜ finetuneì„ ìœ„í•œ í™•ì¥ì„±ìˆê³ , í¸ë¦¬í•˜ë©°, íš¨ìœ¨ì ì¸ toolboxë¡œ, user-friendlyí•  ë¿ë§Œ ì•„ë‹ˆë¼ speedyí•˜ê³  reliableí•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìœ¼ë©°, ëª¨ë“  ìœ ì €ë“¤ì´ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ëª¨ë‘ë¥¼ ìœ„í•œ Large Language Model. See our [vision](https://github.com/OptimalScale/LMFlow#vision).

<p align="center" width="100%">
<img src="../assets/features.png" alt="LMFlow-features" style="width: 100%; min-width: 300px; display: block; margin: auto;">
</p>


## Latest News
* [2023-04-02] [Web service is online!](https://lmflow.com/)
* [2023-04-01] [Release Chinese checkpoints in model zoo: LLaMA-7B-tuned, LLaMA-13B-tuned, LLaMA-33B-tuned.](https://github.com/OptimalScale/LMFlow#model-zoo)
* [2023-04-01] [Release English checkpoints in model zoo: LLaMA-7B-medical, LLaMA-13B-medical, and LLaMA-33B-medical.](https://github.com/OptimalScale/LMFlow#model-zoo)
* [2023-03-27] [Support full tuning and lora tuning for all decoder models.](https://github.com/OptimalScale/LMFlow#supported-models) 
* [2023-03-27] [Tasked tuned model beats ChatGPT on medical domain](https://github.com/OptimalScale/LMFlow#model-performance)
* [2023-03-27] [Release code and checkpoints - version 0.0.1](https://optimalscale.github.io/LMFlow/)


## Demos

### í˜„ì¬ ì²´í¬í¬ì¸íŠ¸ ë‹¤ìš´ë¡œë“œ ì„œë¹„ìŠ¤ê°€ capacityë¥¼ ì´ˆê³¼í–ˆê³ , ìš°ë¦¬ëŠ” ì´ë¥¼ ì§€ì›í•˜ê¸° ìœ„í•´ í•˜ë‚˜ì˜ ì„œë²„ë¥¼ ë” í• ë‹¹í–ˆìŠµë‹ˆë‹¤. "_too many HTTP requests_", ë¼ëŠ” ì—ëŸ¬ê°€ ë°œìƒí•œë‹¤ë©´ ëª‡ ë¶„ ì •ë„ ê¸°ë‹¤ë ¸ë‹¤ê°€ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”. ì–‘í•´í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.:pray:

ìš°ë¦¬ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë„¤ ê°€ì§€ ì¢…ë¥˜ì˜ ë°ëª¨ë¥¼ ì œê³µí•©ë‹ˆë‹¤:
- ì˜¨ë¼ì¸ ì„œë¹„ìŠ¤: ìš°ë¦¬ëŠ” ì§ì ‘ì ì¸ ì½”ë“œ ì‹¤í–‰ ì—†ì´ ì €í¬ ëª¨ë¸ì„ ì‹œë„í•´ ë³´ê³  ì‹¶ìœ¼ì‹  ë¶„ë“¤ì„ ìœ„í•´ì„œ instruction-tuned LLaMA-7Bì™€ LLaMA-33B ë°°í¬í•˜ì˜€ìŠµë‹ˆë‹¤.
- ì½”ë© ì±—ë´‡ (shell): ì‰˜ ê¸°ë°˜ì˜ ìƒí˜¸ì‘ìš© ì±—ë´‡ìœ¼ë¡œ ì½”ë©ì—ì„œ ì‰½ê²Œ ì±—ë´‡ì„ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ì½”ë© ì±—ë´‡ (web): ì›¹ ê¸°ë°˜ì˜ ìƒí˜¸ì‘ìš© ì±—ë´‡ìœ¼ë¡œ ì½”ë©ì—ì„œ ìì‹ ë§Œì˜ ì±—ë´‡ì„ ì‰½ê²Œ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ë¡œì»¬ ë°°í¬: ìš°ë¦¬ëŠ” ë¡œì»¬ì—ì„œ ëª¨ë¸/ì±—ë´‡ì„ ë°°í¬í•  ìˆ˜ ìˆëŠ” ë°©ë²• ë˜í•œ ì œê³µí•˜ê¸° ë•Œë¬¸ì—, ì¶©ë¶„í•œ ìì›ì´ ìˆë‹¤ëŠ” ì „ì œ í•˜ì— ì´ì „ ì„¸ ê°€ì§€ ë°©ë²•ë³´ë‹¤ í›¨ì”¬ í° ëª¨ë¸ì„ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


[![Code License](https://img.shields.io/badge/Online%20Service-Web-green.svg)](https://lmflow.com)
[![colab badge](https://img.shields.io/badge/Colab-(shell)%20%20chatbot:%20gpt--neo-orange?logo=google-colab&amp)](https://colab.research.google.com/drive/1P9Hf6_mLE7WHH92pw73j9D5kz6GTdkow?usp=sharing)
[![colab badge](https://img.shields.io/badge/Colab-(web)%20%20chatbot:%20gpt--neo-blue?logo=google-colab&amp)](https://colab.research.google.com/drive/1LLtiiQO-ZIIFsTKxYzGWYX9BDRc-v8dq?usp=sharing)


### Online Service
> ì €í¬ [ì›¹ ì„œë¹„ìŠ¤ë¥¼](https://lmflow.com/) ë°©ë¬¸í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” LLaMA-7B-tunedì™€ LLaMA-33B-tunedë¥¼ ë¯¸ë¦¬ë³´ê¸°ë¡œ ë°°í¬í•´ ë†“ì•˜ìŠµë‹ˆë‹¤. ê°€ë” ì›¹ì‚¬ì´íŠ¸ íŠ¸ë˜í”½ì´ ë§ì€ ê²½ìš°ì— ì›¹ì‚¬ì´íŠ¸ê°€ ì‘ë‹µí•˜ì§€ ëª»í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì´ ë¿ë§Œ ì•„ë‹ˆë¼, `Local Deploy`ë¥¼ ì°¸ì¡°í•˜ì—¬ ë°°í¬í•´ë³´ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Colab chatbot(shell)
<p align="center" width="100%">
<img src="../assets/colab-shell-chatbot-demo.png">
</p>

ìš°ë¦¬ëŠ” êµ¬ê¸€ ì½”ë©ì˜ T4/P100/V100 GPUë¥¼ ì´ìš©í•œ ê°„ë‹¨í•œ ì‰˜ ë°ëª¨ ì±—ë´‡ì„ ì œê³µí•©ë‹ˆë‹¤. ì œê³µëœ gpt-neo-2.7b ëª¨ë¸ì€ ì˜ì–´ë§Œ ì§€ì›í•˜ë©° ë•Œë•Œë¡œ ë§Œì¡±ìŠ¤ëŸ½ì§€ ì•Šì€ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ìˆëŠ” ë‹¤ë¥¸ ëª¨ë¸ë“¤ì— ë¹„í•´ ì•½í•œ í¸ì´ë¼ëŠ” ì ì— ìœ ì˜í•˜ì‹­ì‹œì˜¤. ì‚¬ìš©ìëŠ” LMFlowì„ í†µí•´ ìì‹ ì˜ ë°ì´í„°ì…‹ì— ëª¨ë¸ì„ finetuneí•˜ê³  ë” ë‚˜ì€ ì„±ëŠ¥ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ğŸ¤— [huggingface](https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads)ì—ì„œ ì œê³µí•˜ëŠ” ë‹¤ë¥¸ decoder-only ëª¨ë¸ë“¤ ë˜í•œ ë‹¤ìŒê³¼ ê°™ì´ ì‹œë„í•´ ë³¼ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:

```sh
./scripts/run_chatbot.sh {another-model-name}
```




### Colab chatbot(web)
ìš°ë¦¬ëŠ” êµ¬ê¸€ ì½”ë©ì˜ T4/P100/V100 GPUë¥¼ ì´ìš©í•œ ê°„ë‹¨í•œ ì›¹ ë°ëª¨ ì±—ë´‡ì„ ì œê³µí•©ë‹ˆë‹¤. ì œê³µëœ gpt-neo-2.7b ëª¨ë¸ì€ ì˜ì–´ë§Œ ì§€ì›í•˜ë©° ë•Œë•Œë¡œ ë§Œì¡±ìŠ¤ëŸ½ì§€ ì•Šì€ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ìˆëŠ” ë‹¤ë¥¸ ëª¨ë¸ë“¤ì— ë¹„í•´ ì•½í•œ í¸ì´ë¼ëŠ” ì ì— ìœ ì˜í•˜ì‹­ì‹œì˜¤.

### Local Deploy
ë§Œì•½ ì¶©ë¶„í•œ ìì›ì´ ìˆê³  ëª¨ë¸ì„ ë¡œì»¬ì—ì„œ ë°°í¬í•˜ê³  ì‹¶ì–´í•˜ëŠ” ìœ ì €ë¥¼ ìœ„í•´, ìš°ë¦¬ëŠ” ë°±ì—”ë“œ(ë‹¤ë¥¸ í”„ë¡ íŠ¸ì—”ë“œì— ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´)ì™€ interactive ì›¹ í”„ë¡ íŠ¸ì—”ë“œ(ì§ì ‘ ëŒ€í™”í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ”)ì˜ launchë¥¼ ìœ„í•œ í”Œë¼ìŠ¤í¬ ì„œë²„ë¥¼ ì‰½ê²Œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤. ë‹¤ìŒê³¼ ê°™ì´ í•˜ì‹­ì‹œì˜¤
```sh
cd ./service
python app.py
```

## Medical Performance

|                |  PubMedQA (ID) | MedQA-USMLE (OOD) | MedMCQA (ID) |  Average |
|:---------:|:--------:|:-----------:|:-------:|:----:|
| Human (pass)   |  60.0   |     50.0    |         |      |
| Human (expert) |    78.0   |     87.0    |  90.0   | 85.0 |
|   |      |              |    |  |
|  InstructGPT 175B   |   73.2   |     46.0    |  44.0   | 54.4 |
|    ChatGPT |    63.9   |     **57.0**    |  44.7   | 55.2 |
|      LLaMA 7B   |    5.2   |     27.1    |  24.3   | 18.9 |
|      LLaMA 33B |    1.8   |     43.4    |  30.3   | 25.2 |
|   |      |             |            |    |  |
|   Task-tuned LLaMA 7B (Full) |   **75.1**   |     44.5    |  49.9   | 56.5 |
| Task-tuned LLaMA 33B (LoRA) |  74.0  |  51.3   | **50.2**|**58.5**|


LLaMA 33B (LoRA)ì˜ ì„±ëŠ¥ì€ ë‹¨ì¼ 8 \* A100 ì„œë²„ë¡œ PubMedQAì™€ MedMCQAì˜ í•™ìŠµ ë¶„í• ì— ëŒ€í•´ ~16ì‹œê°„ë§Œ finetuneí•˜ì—¬ ë‹¬ì„±ë˜ì—ˆìŠµë‹ˆë‹¤. Instruction tuning ê²°ê³¼ë¥¼ í¬í•¨í•œ ë” ë§ì€ ì„±ëŠ¥ì€ í•´ë‹¹ [ë¬¸ì„œ](https://optimalscale.github.io/LMFlow/) ë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.

## Model Zoo
ìš°ë¦¬ëŠ” í•™ìŠµëœ ì²´í¬í¬ì¸íŠ¸ë“¤ì„ ëª¨ë‘ê°€ ì¶”ê°€ í•™ìŠµ ë° ì¶”ë¡ ì„ í•  ìˆ˜ ìˆê²Œ ì˜¤í”ˆì†ŒìŠ¤ë¡œ ì œê³µí•©ë‹ˆë‹¤.

| Instruct-tuned Models   |  Status | Base Model | Download | 
|----------|:-------------:|----------|:-------------:|
| LLaMA-7B-tuned | ![completed](https://geps.dev/progress/100) | LLaMA-7B | [Google Drive](https://drive.google.com/file/d/1x5JLae3akVkfFeDhSe3TEyUbPn_GNFyb/view?usp=share_link) |
| LLaMA-13B-tuned | ![completed](https://geps.dev/progress/100) | LLaMA-13B |  [Google Drive](https://drive.google.com/file/d/1m_rpe6rNpN59kWvjJ3GfKeEmS-68TRYr/view?usp=share_link) |
| LLaMA-33B-tuned | ![completed](https://geps.dev/progress/100) |LLaMA-33B |  [Google Drive](https://drive.google.com/file/d/1IqgqLHwNkWQ7BffheZnqD6a-8Zul1bk6/view?usp=share_link) |
| LLaMA-65B-tuned | ![training](https://geps.dev/progress/65) | LLaMA-65B | Google Drive |
| LLaMA7B-medical | ![completed](https://geps.dev/progress/100) | LLaMA-7B | [Google Drive](https://drive.google.com/file/d/1Z44tsrRvfDFvucbNGFjHC_vbPcBvg3x-/view?usp=share_link) |
| LLaMA13B-medical | ![completed](https://geps.dev/progress/100) | LLaMA-13B |  [Google Drive](https://drive.google.com/file/d/1uoTAXTMyYQkP6N4ummx7tj-c4v1p91ap/view?usp=share_link) |
| LLaMA33B-medical | ![completed](https://geps.dev/progress/100) |LLaMA-33B |  [Google Drive](https://drive.google.com/file/d/14N9o_1pwHmVuSikQ3orMVzZDrLYJC0iM/view?usp=share_link) |
| LLaMA65B-medical | ![training](https://geps.dev/progress/90) | LLaMA-65B | Google Drive |


## Supported Pipelines

| Pipelines   |   Status |
|----------|:-------------:|
| Task Tuning |  :white_check_mark: Supported |
| Instruction Tuning |  :white_check_mark: Supported |
| Parameter-Efficient Tuning |  :white_check_mark: Supported |
| Large Model Inference |  :white_check_mark: Supported |
| Alignment Tuning |  :wrench: Developing |



## Supported Models

ğŸ¤— huggingfaceì˜ ëª¨ë“  [ë””ì½”ë” ëª¨ë¸](https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads) ì„ ì›í™œí•˜ê²Œ ì§€ì›í•©ë‹ˆë‹¤. LLaMA, GPT2, GPT-Neo, Galactica ë“±ì€ ì™„ì „íˆ í…ŒìŠ¤íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ê³§ ì¸ì½”ë” ëª¨ë¸ë„ ì§€ì›í•  ì˜ˆì •ì…ë‹ˆë‹¤.


## 1.Setup

ì†Œí”„íŠ¸ì›¨ì–´ íŒ¨í‚¤ì§€ëŠ” Linux ìš´ì˜ ì²´ì œ(Ubuntu 20.04)ì—ì„œ ì™„ì „íˆ í…ŒìŠ¤íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ìš´ì˜ ì²´ì œ í”Œë«í¼(MacOS, Windows)ì€ ì•„ì§ ì™„ì „íˆ í…ŒìŠ¤íŠ¸ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.Linux ì‹œìŠ¤í…œì—ì„œ ë¨¼ì € ì‹œë„í•˜ê±°ë‚˜ Google Colabì„ ì‚¬ìš©í•˜ì—¬ ê²½í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
git clone https://github.com/OptimalScale/LMFlow.git
cd LMFlow
conda create -n lmflow python=3.9 -y
conda activate lmflow
conda install mpi4py
pip install -e .
```

## 2.Prepare Dataset
ë‹¤ìŒì„ ì‹¤í–‰í•˜ë©´ ì˜ˆì œ í•™ìŠµ ë°ì´í„°ì…‹ê³¼ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì„ ì‰½ê²Œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```bash
cd data
bash download.sh all
cd -
``` 

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ê°„ë‹¨íˆ ë³€í™˜í•˜ë©´ ìì‹ ì˜ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:
```json
{
  "type": "text2text",
  "instances": [
    {
      "input": "Question: The Transformer architecture [START_REF]",
      "output": "N/A"
    },
    ...
  ]
}
```
```json
{
  "type": "text_only",
  "instances": [
    {
      "text": "Defintion: In this task, we ask you to write an answer to a question that involves events that may be stationary (not changing over time) or transient (changing over time). For example, the sentence \"he was born in the U.S.\" contains a stationary event since it will last forever; however, \"he is hungry\" contains a transient event since it will remain true for a short period of time. Note that a lot of the questions could have more than one correct answer. We only need a single most-likely answer. Please try to keep your \"answer\" as simple as possible. Concise and simple \"answer\" is preferred over those complex and verbose ones. \n Input: Question: Sentence: It's hail crackled across the comm, and Tara spun to retake her seat at the helm. \nQuestion: Will the hail storm ever end? \n Output: NA \n\n"
    },
    ...
  ]
}
```
## 3. Run Scripts
### 3.1 Run Finetuning

`scripts/run_finetune.sh` ë¥¼ ì‹¤í–‰í•˜ì—¬ GPT-2 ë² ì´ìŠ¤ ëª¨ë¸ì„ finetuneí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```sh
./scripts/run_finetune.sh
```

ìì‹ ì˜ ê¸°ê³„ ì„¤ì •ì„ ë°˜ì˜í•˜ê¸° ìœ„í•´ deepspeedì— argumentsë¥¼ ì œê³µí•˜ê³  ì‹¶ë‹¤ë©´, í•´ë‹¹í•˜ëŠ” deepspeed argumentsë¥¼ ìŠ¤í¬ë¦½íŠ¸ì— ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ë©´,
```sh
./scripts/run_finetune.sh "--num_gpus=8 --master_port 10001"
```

LoRA finetuningì„ í™œì„±í™”í•˜ë ¤ë©´, ì•„ë˜ë¥¼ ì°¸ê³ í•˜ì—¬
```sh
./scripts/run_finetune_with_lora.sh
```
ë¹„ìŠ·í•œ ë°©ì‹ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ìì„¸í•œ ì„¤ì •ì€ ì´ ìŠ¤í¬ë¦½íŠ¸ë“¤ì„ ì§ì ‘ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ìŠ¤í¬ë¦½íŠ¸ë“¤ì€ ì‹¤ì œë¡œëŠ” íŒŒì´ì¬ ìŠ¤í¬ë¦½íŠ¸ `examples/finetune.py`, ë¥¼ í˜¸ì¶œí•˜ëŠ”ë°, ì´ê²ƒì€ ë‹¤ìŒê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤,

```sh
deepspeed ${deepspeed_args} \
  examples/finetune.py \
    --deepspeed configs/ds_config_zero3.json \
    --bf16 \
    --run_name finetune_with_lora \
    --model_name_or_path facebook/galactica-1.3b \
    --num_train_epochs 0.01 \
    --learning_rate 2e-5 \
    --dataset_path ${dataset_path} \
    --per_device_train_batch_size 1 \
    --per_device_eval_batch_size 1 \
    --validation_split_percentage 0 \
    --logging_steps 20 \
    --block_size 512 \
    --do_train \
    --output_dir output_models/finetune \
    --overwrite_output_dir \
    --ddp_timeout 72000 \
    --save_steps 5000 \
    --dataloader_num_workers 1
```
ì—¬ê¸°ì„œëŠ”`--num_train_epochs` ì˜ epoch ìˆ˜ë¥¼ `0.01` ë¡œ ì„¤ì •í•˜ì—¬ finetuning í”„ë¡œì„¸ìŠ¤ë¥¼ ë¹ ë¥´ê²Œ ì™„ë£Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë” ë‚˜ì€ ì„±ëŠ¥ì˜ ëª¨ë¸ì„ ì–»ê³  ì‹¶ë‹¤ë©´ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ì‹­ì‹œì˜¤. ëª¨ë“  ê°€ëŠ¥í•œ finetuning argumentsë¥¼ ë³¼ ìˆ˜ ìˆë„ë¡
```python
python examples/finetune.py -h
```
ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. finetuned ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ëŠ” ìœ„ì˜ ì˜ˆì—ì„œ `--output_dir`, ë¡œ ì§€ì •ëœ ì¸ìì— ì €ì¥ë©ë‹ˆë‹¤. ì´ ê²½ìš°ì—ëŠ”
`output_models/finetune` ì…ë‹ˆë‹¤.
### 3.2 Run Evaluation

ê¸°ì¡´ huggingface ëª¨ë¸ë¡œ ì§ì ‘ í‰ê°€ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ GPT2 largeë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ ë‹¤ìŒì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```sh
./scripts/run_evaluation.sh
```
ë˜ëŠ” í•´ë‹¹ íŒŒì´ì¬ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```python
CUDA_VISIBLE_DEVICES=0 \
    deepspeed examples/evaluate.py \
    --answer_type medmcqa \
    --model_name_or_path gpt2-large \
    --dataset_path data/MedQA-USMLE/validation \
    --deepspeed examples/ds_config.json
```
finetuned ëª¨ë¸ì„ ë¡œë“œí•˜ë ¤ë©´ ì €ì¥ëœ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì—¬ `--model_name_or_path` ë¥¼ ì§€ì •í•˜ì‹­ì‹œì˜¤.

LoRA finetuned ëª¨ë¸ì˜ ê²½ìš° ë‹¤ìŒì„ ì°¸ì¡°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
```sh
./scripts/run_evaluation_with_lora.sh
```

ì´ëŸ¬í•œ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì €í¬ì˜ APIë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•ëœ ì˜ˆì œ `examples/*.py` ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤. ë” ë§ì€ API ê´€ë ¨ ì˜ˆì œëŠ” unittestì˜ ë©”ì†Œë“œë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.
`tests`.

## 4. Additional Notes
### 4.1 LLaMA Checkpoint

1. ë¨¼ì € [facebookresearch/llama](https://github.com/facebookresearch/llama). ì—ì„œ LLaMA ëª¨ë¸ì— ëŒ€í•œ ì•¡ì„¸ìŠ¤ ê¶Œí•œì„ ì–»ì–´ì•¼í•©ë‹ˆë‹¤. ê³µì‹ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³   `${llama-path}` ì— ì €ì¥í•˜ì‹­ì‹œì˜¤..

2. ë‘ ë²ˆì§¸ë¡œ, ì•„ë˜ì˜ ì»¤ë§¨ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ ê³µì‹ ì²´í¬í¬ì¸íŠ¸ `${llama-path}` ë¥¼ HuggingFaceê°€ ì§€ì›í•˜ëŠ” ì²´í¬í¬ì¸íŠ¸ `${llama-hf-path}` ë¡œ ë³€í™˜í•˜ì‹­ì‹œì˜¤.

    `python ./scripts/convert_llama_weights_to_hf.py --input_dir ${llama-path} --model_size 7B --output_dir ${llama-hf-path}/llama-7b-hf`

3. ê·¸ëŸ° ë‹¤ìŒ `${llama-hf-path}/llama-7b-hf`ë¡œ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œë¥¼ ì„¤ì •í•˜ë©´ ì¤€ë¹„ ì™„ë£Œì…ë‹ˆë‹¤. ì¦ê²¨ë³´ì„¸ìš”!

4. (ì„ íƒ ì‚¬í•­) ì´ì œ ì›ë˜ llama-7b-hf ì‚¬ì „ í•™ìŠµ ëª¨ë¸ì´ ìˆìŠµë‹ˆë‹¤.
```sh
cd output_models && ./download.sh all && cd -
```
`./scripts/run_evaluation_with_lora.sh`ì™€ ìœ ì‚¬í•œ ë°©ì‹ìœ¼ë¡œ ë‹¤ìŒì„ ì‹¤í–‰í•˜ì—¬ ì €í¬ê°€ finetuningí•œ ëª¨ë¸ differenceë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤,
```sh
CUDA_VISIBLE_DEVICES=0 \
    deepspeed examples/evaluate.py \
    --answer_type text \
    --model_name_or_path ${llama-hf-path}/llama-7b-hf \
    --lora_model_path output_models/${llama-model-diff-path} \
    --dataset_path data/alpaca/test \
    --prompt_structure "Input: {input}" \
    --deepspeed examples/ds_config.json
```
ì´ì œ finetuningëœ llama ëª¨ë¸ë¡œ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### 4.2 DeepSpeed Config
configëŠ” configs ì•„ë˜ì—ì„œ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [DeepSpeed Configuration](https://www.deepspeed.ai/docs/config-json/)  ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.

## 5. Model Release

### 5.1 Medical Model Checkpoints
ë‹¤ìŒ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ ì €í¬ì˜ ì˜ë£Œ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
cd output_models
bash download.sh medical_ckpt
cd -
```
ë˜í•œ ë‹¤ìŒ Google ë“œë¼ì´ë¸Œ ë§í¬ë¥¼ í†µí•´ ì§ì ‘ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ : [medical_ckpt.tar.gz](https://drive.google.com/file/d/1bnsQGNGNYchsOfiNyRAmL2fNiowbmFNw/view?usp=share_link)

### 5.2 Instruction Model Checkpoints
ë§ˆì°¬ê°€ì§€ë¡œ ë‹¤ìŒ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ ì €í¬ì˜ instruction ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
```bash
cd output_models
bash download.sh instruction_ckpt
cd -
```

ë§ˆì°¬ê°€ì§€ë¡œ ë‹¤ìŒ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ ì €í¬ì˜ instruction ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ : [instruction_ckpt.tar.gz](https://drive.google.com/file/d/1d_ioQ-ViVweeifbsFSO4pczc3UORFHZO/view?usp=share_link)

### 5.3 Begin Reproduce

ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œ í•œ í›„ì—ëŠ” `--lora_model_path` ë¥¼ `output_models/instruction_ckpt/llama7b-lora`  (llama-7b for instructionì˜ ì˜ˆì‹œ)ë¡œ ëŒ€ì²´í•˜ê³  `--model_name_or_path` ë¥¼ `LMFlow/scripts/run_evaluation_with_lora.sh` ë‚´ë¶€ì˜ ë³€í™˜ ëœ llama ëª¨ë¸ë¡œ ëŒ€ì²´ í•œ ë‹¤ìŒ ì´ ì…¸ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ ì¬í˜„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ê·¸ëŸ° ë‹¤ìŒ [Doc](https://optimalscale.github.io/LMFlow/) ì—ì„œ ëª¨ë¸ ì„±ëŠ¥ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

## Documentation
ë” ë§ì€ API ì°¸ì¡° ë° ì‹¤í—˜ ê²°ê³¼ëŠ” [Documentation](https://optimalscale.github.io/LMFlow/) ë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.

## Vision
ì•ˆë…•í•˜ì„¸ìš”! ìš°ë¦¬ëŠ” ì™„ì „í•œ LLM í•™ìŠµ í”„ë¡œì„¸ìŠ¤ë¥¼ í¬í•¨í•˜ì—¬ ì‚¬ìš©ìê°€ ìì‹ ì˜ ì–¸ì–´ ëª¨ë¸ì„ ë¹ ë¥´ê²Œ êµ¬ì¶•í•˜ê³  íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµ í•  ìˆ˜ ìˆë„ë¡í•˜ëŠ” ì½”ë“œ repositoryê°€ ê³§ ì¶œì‹œ ë  ê²ƒì„ ë°œí‘œí•˜ê²Œ ë˜ì–´ ê¸°ì©ë‹ˆë‹¤.

ìš°ë¦¬ì˜ ì½”ë“œ repositoryëŠ” ë‹¨ìˆœí•œ ëª¨ë¸ì´ ì•„ë‹ˆë©° ì™„ì „í•œ í•™ìŠµ ì›Œí¬ í”Œë¡œ, ëª¨ë¸ ìµœì í™” ë° í…ŒìŠ¤íŠ¸ ë„êµ¬ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ëŒ€í™” ëª¨ë¸, ì§ˆë¬¸-ë‹µë³€ ëª¨ë¸ ë° ê¸°íƒ€ í…ìŠ¤íŠ¸ ìƒì„± ëª¨ë¸ì„ ë¹„ë¡¯í•œ ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì–¸ì–´ ëª¨ë¸ì„ êµ¬ì¶•í•˜ëŠ” ë° ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë˜í•œ ìš°ë¦¬ëŠ” LLM ê³µìœ  í”Œë«í¼ì„ ë§Œë“¤ì–´ ì‚¬ëŒë“¤ì´ ì²´í¬í¬ì¸íŠ¸ì™€ ê²½í—˜ì„ ê³µìœ í•˜ì—¬ ì»¤ë®¤ë‹ˆí‹°ì˜ ê¸°ìˆ ì„ í•¨ê»˜ ê°œì„ í•  ìˆ˜ ìˆëŠ” ê°œë°©ì ì´ê³  ë¯¼ì£¼ì ì¸ LLM ê³µìœ  í”Œë«í¼ì„ ë§Œë“¤ê³ ìí•©ë‹ˆë‹¤. LLMì— ê´€ì‹¬ìˆëŠ” ëˆ„êµ¬ë‚˜ ì°¸ì—¬í•˜ì—¬ ì¹œê·¼í•˜ê³  ê°œë°©ì ì¸ ì»¤ë®¤ë‹ˆí‹°ë¥¼ ë§Œë“¤ì–´ ê°€ëŠ” ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!

ì´ˆë³´ìë“  ì „ë¬¸ê°€ë“  ìƒê´€ì—†ì´ ì´ í”Œë«í¼ì—ì„œ í˜œíƒì„ ë°›ì„ ìˆ˜ ìˆì„ ê²ƒì´ë¼ê³  ë¯¿ìŠµë‹ˆë‹¤. í•¨ê»˜ í™œê¸°ì°¨ê³  í˜ì‹ ì ì¸ LLM ì»¤ë®¤ë‹ˆí‹°ë¥¼ ë§Œë“¤ì–´ ë´…ì‹œë‹¤!

[![Embark](https://img.shields.io/badge/discord-LMFlow-%237289da.svg?logo=discord)](https://discord.gg/srGxyazbNs)
[![slack badge](https://img.shields.io/badge/Slack-join-blueviolet?logo=slack&amp)](https://join.slack.com/t/lmflow/shared_invite/zt-1s6egx12s-THlwHuCjF6~JGKmx7JoJPA)
[![WeChat badge](https://img.shields.io/badge/WeChat-Join-brightgreen?logo=wechat&amp)](https://i.328888.xyz/2023/04/04/ibvpAk.jpeg)

## Disclaimer

ì´ íŒ¨í‚¤ì§€ëŠ” ëŒ€í˜• ëª¨ë¸ íŠœë‹ì„ ìœ„í•œ ê°„ì†Œí™” ëœ ì‚¬ìš©ì ì¹œí™”ì ì¸ íŒŒì´í”„ ë¼ì¸ì„ ì œê³µí•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œí•©ë‹ˆë‹¤. ê·¸ ê¸°ëŠ¥ì€ ì°¸ì¡° ìš©ë„ë¡œ ì œê³µë˜ë©° ì‚¬ìš©ìê°€ ì‚¬ìš©í•˜ë„ë¡ ì˜ë„ë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë°ì´í„° ë° ì‚¬ì „ í•™ìŠµ ëœ ëª¨ë¸ì˜ ì¤€ë¹„ ì±…ì„ì€ ì‚¬ìš©ìì—ê²Œ ë‹¬ë ¤ ìˆìŒì„ ëª…ì‹¬í•´ì•¼í•©ë‹ˆë‹¤. ì´ íŒ¨í‚¤ì§€ëŠ” ì‚¬ìš©ì ì¤€ë¹„ êµ¬ì„± ìš”ì†Œì˜ ì •í™•ì„±, ì™„ì „ì„±, ì ìš© ê°€ëŠ¥ì„± ë˜ëŠ” ë²•ì  ì í•©ì„±ì„ ë³´ì¦í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì‚¬ìš©ìëŠ” ëª¨ë¸ ë° ë°ì´í„°ì˜ ì¤€ë¹„ì™€ ê´€ë ¨ëœ ëª¨ë“  ìœ„í—˜ê³¼ ì±…ì„ì„ ì¸ì‹í•˜ê³  ê°€ì •í•˜ê³  ì´ íŒ¨í‚¤ì§€ë¥¼ í™œìš©í•˜ê¸° ì „ì— ë²•ì , ìƒì—…ì  ë° ê¸°ìˆ ì  ìë¬¸ì„ ë°›ì•„ì•¼í•©ë‹ˆë‹¤. íŒŒì´í”„ ë¼ì¸ì€ ì‚¬ìš©ìì˜ ì˜ëª»ëœ ë°ì´í„° ë° ì‚¬ì „ í•™ìŠµ ëœ ëª¨ë¸ì˜ ì¤€ë¹„ë¡œ ì¸í•œ ì–´ë– í•œ ì§ì ‘ì ì¸, ê°„ì ‘ì ì¸, íŠ¹ìˆ˜, ë¶€ìˆ˜ì  ë˜ëŠ” ê²°ê³¼ì  ì†í•´ì— ëŒ€í•´ì„œë„ ì±…ì„ì„ ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤.

ì˜ì–´ì™€ ì¤‘êµ­ì–´ ë²„ì „ ëª¨ë‘ë¥¼ í¬í•¨í•˜ëŠ” ì ê²€ í¬ì¸íŠ¸ëŠ” ì—°êµ¬ ëª©ì ìœ¼ë¡œë§Œ ì œê³µë©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì²´í¬ í¬ì¸íŠ¸ì— í¬í•¨ ëœ êµìœ¡ ë°ì´í„°ì—ëŠ” ChatGPT ì–¸ì–´ ëª¨ë¸ì—ì„œ ìƒì„± ëœ ê²°ê³¼ê°€ í¬í•¨ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì²´í¬ í¬ì¸íŠ¸ì˜ ë°°í¬ ë˜ëŠ” ì‚¬ìš©ì„ ë³´ì¦í•˜ê±°ë‚˜ ì¥ë ¤í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì²´í¬ í¬ì¸íŠ¸ì˜ ì‚¬ìš©ìëŠ” ì˜¬ë°”ë¥´ê³  ì ì ˆí•˜ê²Œ ì‚¬ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ê²ƒì´ ì „ì ìœ¼ë¡œ ê·¸ë“¤ì˜ ì±…ì„ì…ë‹ˆë‹¤.

ë˜í•œ ëª¨ë¸ì—ì„œ ìƒì„± ëœ ê²°ê³¼ëŠ” í™•ë¥  ëª¨ë¸ì— ê¸°ë°˜í•˜ë©° ì§ì ‘ì ìœ¼ë¡œ ì´ íŒŒì´í”„ ë¼ì¸ê³¼ ê´€ë ¨ì´ ì—†ìŒì„ ê°•ì¡°í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ê²°ê³¼ì˜ ì •í™•ì„±, ì‹ ë¢°ì„±, ì ìš© ê°€ëŠ¥ì„± ë° ë²•ì  ì í•©ì„±ì€ ì´ íŒŒì´í”„ ë¼ì¸ì—ì„œ ë³´ì¦ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì‚¬ìš©ìëŠ” ê²°ê³¼ì™€ ê´€ë ¨ëœ ìœ„í—˜ê³¼ ì±…ì„ë„ ì¸ì‹í•´ì•¼í•˜ë©° ëª¨ë¸ì—ì„œ ìƒì„± ëœ ê²°ê³¼ì— ì˜ì¡´í•˜ê¸° ì „ì— ë²•ì , ìƒì—…ì  ë° ê¸°ìˆ ì  ìë¬¸ì„ ë°›ì•„ì•¼í•©ë‹ˆë‹¤. íŒŒì´í”„ ë¼ì¸ì€ ì‚¬ìš©ìê°€ ëª¨ë¸ì—ì„œ ìƒì„± í•œ ê²°ê³¼ì— ì˜ì¡´í•˜ì—¬ ë°œìƒí•˜ëŠ” ì–´ë– í•œ ì§ì ‘ì ì¸, ê°„ì ‘ì ì¸, íŠ¹ìˆ˜, ë¶€ìˆ˜ì  ë˜ëŠ” ê²°ê³¼ì  ì†í•´ì— ëŒ€í•´ì„œë„ ì±…ì„ì„ ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤.

## Support

ë„ì›€ì´ í•„ìš”í•˜ë©´ [Github](https://github.com/OptimalScale/LMFlow)ì— ë¬¸ì œë¥¼ ì œì¶œí•˜ì‹­ì‹œì˜¤.

## Contributors
<a href="https://github.com/OptimalScale/LMFlow/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=OptimalScale/LMFlow" />
</a>

## Citation
ì´ repositoryë¥¼ ìœ ìš©í•˜ê²Œ ì‚¬ìš©í•˜ì…¨ë‹¤ë©´ â­ì„ ëˆŒëŸ¬ì£¼ì‹œê³  citeí•´ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤:

```
@misc{lmflow,
  author = {Shizhe Diao and Rui Pan and Hanze Dong and KaShun Shum and Jipeng Zhang and Wei Xiong and Tong Zhang},
  title = {LMFlow: An Extensible Toolkit for Finetuning and Inference of Large Foundation Models},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://optimalscale.github.io/LMFlow/}},
}
```
