
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>lmflow.args &#8212; LMFlow  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/lmflow/args';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>
<aside class="bd-header-announcement" aria-label="Announcement">
  <div class="bd-header-announcement__content">We've released our memory-efficient finetuning algorithm LISA, check out [<a href='https://arxiv.org/pdf/2403.17919.pdf'>Paper</a>][<a href='https://github.com/OptimalScale/LMFlow#finetuning-lisa'>User Guide</a>] for more details!</div>
</aside>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">LMFlow</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../blogs/index.html">
    Blogs
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../examples/index.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../autoapi/index.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../about/index.html">
    About
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
            
          
          
          
          
          
          
          
          
          
          <a href="https://github.com/OptimalScale/LMFlow" title="LMFlow" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><img src="../../_static/logo5.svg" class="icon-link-image" alt="LMFlow"/></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../blogs/index.html">
    Blogs
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../examples/index.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../autoapi/index.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../about/index.html">
    About
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
            
          
          
          
          
          
          
          
          
          
          <a href="https://github.com/OptimalScale/LMFlow" title="LMFlow" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><img src="../../_static/logo5.svg" class="icon-link-image" alt="LMFlow"/></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../index.html" class="nav-link">Module code</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">lmflow.args</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <h1>Source code for lmflow.args</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python</span>
<span class="sd">&quot;&quot;&quot;This script defines dataclasses: ModelArguments and DatasetArguments,</span>
<span class="sd">that contain the arguments for the model and dataset used in training.</span>

<span class="sd">It imports several modules, including dataclasses, field from typing, Optional from typing,</span>
<span class="sd">require_version from transformers.utils.versions, MODEL_FOR_CAUSAL_LM_MAPPING,</span>
<span class="sd">and TrainingArguments from transformers.</span>

<span class="sd">MODEL_CONFIG_CLASSES is assigned a list of the model config classes from</span>
<span class="sd">MODEL_FOR_CAUSAL_LM_MAPPING. MODEL_TYPES is assigned a tuple of the model types</span>
<span class="sd">extracted from the MODEL_CONFIG_CLASSES.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dataclasses</span><span class="w"> </span><span class="kn">import</span> <span class="n">dataclass</span><span class="p">,</span> <span class="n">field</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Optional</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">MODEL_FOR_CAUSAL_LM_MAPPING</span><span class="p">,</span>
    <span class="n">TrainingArguments</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers.utils.versions</span><span class="w"> </span><span class="kn">import</span> <span class="n">require_version</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">lmflow.utils.versioning</span><span class="w"> </span><span class="kn">import</span> <span class="n">is_flash_attn_available</span>

<div class="viewcode-block" id="MODEL_CONFIG_CLASSES">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.MODEL_CONFIG_CLASSES">[docs]</a>
<span class="n">MODEL_CONFIG_CLASSES</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">MODEL_FOR_CAUSAL_LM_MAPPING</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span></div>

<div class="viewcode-block" id="MODEL_TYPES">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.MODEL_TYPES">[docs]</a>
<span class="n">MODEL_TYPES</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">conf</span><span class="o">.</span><span class="n">model_type</span> <span class="k">for</span> <span class="n">conf</span> <span class="ow">in</span> <span class="n">MODEL_CONFIG_CLASSES</span><span class="p">)</span></div>



<div class="viewcode-block" id="logger">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.logger">[docs]</a>
<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span></div>



<div class="viewcode-block" id="OptimizerNames">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.OptimizerNames">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">OptimizerNames</span><span class="p">:</span>
<div class="viewcode-block" id="OptimizerNames.DUMMY">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.OptimizerNames.DUMMY">[docs]</a>
    <span class="n">DUMMY</span> <span class="o">=</span> <span class="s2">&quot;dummy&quot;</span></div>

<div class="viewcode-block" id="OptimizerNames.ADABELIEF">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.OptimizerNames.ADABELIEF">[docs]</a>
    <span class="n">ADABELIEF</span> <span class="o">=</span> <span class="s2">&quot;adabelief&quot;</span></div>

<div class="viewcode-block" id="OptimizerNames.ADABOUND">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.OptimizerNames.ADABOUND">[docs]</a>
    <span class="n">ADABOUND</span> <span class="o">=</span> <span class="s2">&quot;adabound&quot;</span></div>

<div class="viewcode-block" id="OptimizerNames.LARS">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.OptimizerNames.LARS">[docs]</a>
    <span class="n">LARS</span> <span class="o">=</span> <span class="s2">&quot;lars&quot;</span></div>

<div class="viewcode-block" id="OptimizerNames.LAMB">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.OptimizerNames.LAMB">[docs]</a>
    <span class="n">LAMB</span> <span class="o">=</span> <span class="s2">&quot;lamb&quot;</span></div>

<div class="viewcode-block" id="OptimizerNames.ADAMAX">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.OptimizerNames.ADAMAX">[docs]</a>
    <span class="n">ADAMAX</span> <span class="o">=</span> <span class="s2">&quot;adamax&quot;</span></div>

<div class="viewcode-block" id="OptimizerNames.NADAM">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.OptimizerNames.NADAM">[docs]</a>
    <span class="n">NADAM</span> <span class="o">=</span> <span class="s2">&quot;nadam&quot;</span></div>

<div class="viewcode-block" id="OptimizerNames.RADAM">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.OptimizerNames.RADAM">[docs]</a>
    <span class="n">RADAM</span> <span class="o">=</span> <span class="s2">&quot;radam&quot;</span></div>

<div class="viewcode-block" id="OptimizerNames.ADAMP">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.OptimizerNames.ADAMP">[docs]</a>
    <span class="n">ADAMP</span> <span class="o">=</span> <span class="s2">&quot;adamp&quot;</span></div>

<div class="viewcode-block" id="OptimizerNames.SGDP">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.OptimizerNames.SGDP">[docs]</a>
    <span class="n">SGDP</span> <span class="o">=</span> <span class="s2">&quot;sgdp&quot;</span></div>

<div class="viewcode-block" id="OptimizerNames.YOGI">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.OptimizerNames.YOGI">[docs]</a>
    <span class="n">YOGI</span> <span class="o">=</span> <span class="s2">&quot;yogi&quot;</span></div>

<div class="viewcode-block" id="OptimizerNames.SOPHIA">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.OptimizerNames.SOPHIA">[docs]</a>
    <span class="n">SOPHIA</span> <span class="o">=</span> <span class="s2">&quot;sophia&quot;</span></div>

<div class="viewcode-block" id="OptimizerNames.ADAN">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.OptimizerNames.ADAN">[docs]</a>
    <span class="n">ADAN</span> <span class="o">=</span> <span class="s2">&quot;adan&quot;</span></div>

<div class="viewcode-block" id="OptimizerNames.ADAM">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.OptimizerNames.ADAM">[docs]</a>
    <span class="n">ADAM</span> <span class="o">=</span> <span class="s2">&quot;adam&quot;</span></div>

<div class="viewcode-block" id="OptimizerNames.NOVOGRAD">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.OptimizerNames.NOVOGRAD">[docs]</a>
    <span class="n">NOVOGRAD</span> <span class="o">=</span> <span class="s2">&quot;novograd&quot;</span></div>

<div class="viewcode-block" id="OptimizerNames.ADADELTA">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.OptimizerNames.ADADELTA">[docs]</a>
    <span class="n">ADADELTA</span> <span class="o">=</span> <span class="s2">&quot;adadelta&quot;</span></div>

<div class="viewcode-block" id="OptimizerNames.ADAGRAD">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.OptimizerNames.ADAGRAD">[docs]</a>
    <span class="n">ADAGRAD</span> <span class="o">=</span> <span class="s2">&quot;adagrad&quot;</span></div>

<div class="viewcode-block" id="OptimizerNames.MUON">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.OptimizerNames.MUON">[docs]</a>
    <span class="n">MUON</span> <span class="o">=</span> <span class="s2">&quot;muon&quot;</span></div>

<div class="viewcode-block" id="OptimizerNames.ADAMW_SCHEDULE_FREE">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.OptimizerNames.ADAMW_SCHEDULE_FREE">[docs]</a>
    <span class="n">ADAMW_SCHEDULE_FREE</span> <span class="o">=</span> <span class="s2">&quot;adamw_schedule_free&quot;</span></div>

<div class="viewcode-block" id="OptimizerNames.SGD_SCHEDULE_FREE">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.OptimizerNames.SGD_SCHEDULE_FREE">[docs]</a>
    <span class="n">SGD_SCHEDULE_FREE</span> <span class="o">=</span> <span class="s2">&quot;sgd_schedule_free&quot;</span></div>
</div>



<span class="nd">@dataclass</span>
<div class="viewcode-block" id="ModelArguments">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">ModelArguments</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Define a class ModelArguments using the dataclass decorator.</span>
<span class="sd">    The class contains several optional parameters that can be used to configure a model.</span>

<span class="sd">    model_name_or_path : str</span>
<span class="sd">        a string representing the path or name of a pretrained</span>
<span class="sd">        model checkpoint for weights initialization. If None, a model will be trained from scratch.</span>

<span class="sd">    model_type :  str</span>
<span class="sd">        a string representing the type of model to use if training from</span>
<span class="sd">        scratch. If not provided, a pretrained model will be used.</span>

<span class="sd">    config_overrides :  str</span>
<span class="sd">        a string representing the default config settings to override</span>
<span class="sd">        when training a model from scratch.</span>

<span class="sd">    config_name : str</span>
<span class="sd">        a string representing the name or path of the pretrained config to</span>
<span class="sd">        use, if different from the model_name_or_path.</span>

<span class="sd">    tokenizer_name :  str</span>
<span class="sd">        a string representing the name or path of the pretrained tokenizer</span>
<span class="sd">        to use, if different from the model_name_or_path.</span>

<span class="sd">    cache_dir :  str</span>
<span class="sd">        a string representing the path to the directory where pretrained models</span>
<span class="sd">        downloaded from huggingface.co will be stored.</span>

<span class="sd">    use_fast_tokenizer : bool</span>
<span class="sd">        a boolean indicating whether to use a fast tokenizer (backed by the</span>
<span class="sd">        tokenizers library) or not.</span>

<span class="sd">    model_revision :  str</span>
<span class="sd">        a string representing the specific model version to use (can be a</span>
<span class="sd">        branch name, tag name, or commit id).</span>

<span class="sd">    token : Optional[str]</span>
<span class="sd">        Necessary when accessing a private model/dataset.</span>

<span class="sd">    torch_dtype :  str</span>
<span class="sd">        a string representing the dtype to load the model under. If auto is</span>
<span class="sd">        passed, the dtype will be automatically derived from the model&#39;s weights.</span>

<span class="sd">    use_ram_optimized_load : bool</span>
<span class="sd">        a boolean indicating whether to use disk mapping when memory is not</span>
<span class="sd">        enough.</span>

<span class="sd">    use_int8 : bool</span>
<span class="sd">        a boolean indicating whether to load int8 quantization for inference.</span>

<span class="sd">    load_in_4bit : bool</span>
<span class="sd">        whether to load the model in 4bit</span>

<span class="sd">    model_max_length : int</span>
<span class="sd">        The maximum length of the model.</span>

<span class="sd">    truncation_side : str</span>
<span class="sd">        The side on which the model should have truncation applied.</span>

<span class="sd">    arch_type : str</span>
<span class="sd">        Model architecture type.</span>
<span class="sd">    padding_side : str</span>
<span class="sd">        The side on which the tokenizer should have padding applied.</span>
<span class="sd">    eos_padding : bool</span>
<span class="sd">        whether to pad with eos token instead of pad token.</span>
<span class="sd">    ignore_bias_buffers : bool</span>
<span class="sd">        fix for DDP issues with LM bias/mask buffers - invalid scalar type,`inplace operation.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="ModelArguments.model_name_or_path">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.model_name_or_path">[docs]</a>
    <span class="n">model_name_or_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;The model checkpoint for weights initialization.Don&#39;t set if you want to train a model from scratch.&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.lora_model_path">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.lora_model_path">[docs]</a>
    <span class="n">lora_model_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;The incremental model diff introduced by LoRA finetuning.&quot;</span>
                <span class="s2">&quot; Along with the original non-finetuned model forms the whole&quot;</span>
                <span class="s2">&quot; finetuned model.&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.model_type">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.model_type">[docs]</a>
    <span class="n">model_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;If training from scratch, pass a model type from the list: &quot;</span> <span class="o">+</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">MODEL_TYPES</span><span class="p">)},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.config_overrides">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.config_overrides">[docs]</a>
    <span class="n">config_overrides</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;Override some existing default config settings when a model is trained from scratch. Example: &quot;</span>
                <span class="s2">&quot;n_embd=10,resid_pdrop=0.2,scale_attn_weights=false,summary_type=cls_index&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.arch_type">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.arch_type">[docs]</a>
    <span class="n">arch_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;decoder_only&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;Model architecture type.&quot;</span><span class="p">),</span>
            <span class="s2">&quot;choices&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;decoder_only&quot;</span><span class="p">,</span> <span class="s2">&quot;encoder_decoder&quot;</span><span class="p">,</span> <span class="s2">&quot;text_regression&quot;</span><span class="p">,</span> <span class="s2">&quot;vision_encoder_decoder&quot;</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.config_name">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.config_name">[docs]</a>
    <span class="n">config_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Pretrained config name or path if not the same as model_name&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.tokenizer_name">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.tokenizer_name">[docs]</a>
    <span class="n">tokenizer_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Pretrained tokenizer name or path if not the same as model_name&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.cache_dir">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.cache_dir">[docs]</a>
    <span class="n">cache_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Where do you want to store the pretrained models downloaded from huggingface.co&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.use_fast_tokenizer">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.use_fast_tokenizer">[docs]</a>
    <span class="n">use_fast_tokenizer</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to use one of the fast tokenizer (backed by the tokenizers library) or not.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.model_revision">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.model_revision">[docs]</a>
    <span class="n">model_revision</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;main&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The specific model version to use (can be a branch name, tag name or commit id).&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.token">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.token">[docs]</a>
    <span class="n">token</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;Necessary to specify when accessing a private model/dataset.&quot;</span><span class="p">)},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.trust_remote_code">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.trust_remote_code">[docs]</a>
    <span class="n">trust_remote_code</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;Whether to trust remote code when loading model.&quot;</span><span class="p">)},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.torch_dtype">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.torch_dtype">[docs]</a>
    <span class="n">torch_dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;Override the default `torch.dtype` and load the model under this dtype. If `auto` is passed, the &quot;</span>
                <span class="s2">&quot;dtype will be automatically derived from the model&#39;s weights.&quot;</span>
            <span class="p">),</span>
            <span class="s2">&quot;choices&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="s2">&quot;bfloat16&quot;</span><span class="p">,</span> <span class="s2">&quot;float16&quot;</span><span class="p">,</span> <span class="s2">&quot;float32&quot;</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.use_dora">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.use_dora">[docs]</a>
    <span class="n">use_dora</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to dora, https://github.com/NVlabs/DoRA.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.use_lora">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.use_lora">[docs]</a>
    <span class="n">use_lora</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to lora.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.use_qlora">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.use_qlora">[docs]</a>
    <span class="n">use_qlora</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to use qlora.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.bits">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.bits">[docs]</a>
    <span class="n">bits</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;[deprecated] The number of bits for quantization.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;choices&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.quant_bit">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.quant_bit">[docs]</a>
    <span class="n">quant_bit</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The number of bits for quantization.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;choices&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.quant_type">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.quant_type">[docs]</a>
    <span class="n">quant_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;nf4&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The quantization type for quantization.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;choices&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;nf4&quot;</span><span class="p">,</span> <span class="s2">&quot;fp4&quot;</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.double_quant">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.double_quant">[docs]</a>
    <span class="n">double_quant</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to use double quantization.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.lora_r">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.lora_r">[docs]</a>
    <span class="n">lora_r</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the rank of the lora parameters. The smaller lora_r is , the fewer parameters lora has.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.lora_alpha">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.lora_alpha">[docs]</a>
    <span class="n">lora_alpha</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Merging ratio between the fine-tuned model and the original. This is controlled by a parameter &quot;</span>
            <span class="s2">&quot;called alpha in the paper.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.lora_target_modules">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.lora_target_modules">[docs]</a>
    <span class="n">lora_target_modules</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Model modules to apply LoRA to. Use comma to separate multiple modules.&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.lora_dropout">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.lora_dropout">[docs]</a>
    <span class="n">lora_dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The dropout rate in lora.linear.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.save_aggregated_lora">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.save_aggregated_lora">[docs]</a>
    <span class="n">save_aggregated_lora</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to save aggregated lora.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.use_ram_optimized_load">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.use_ram_optimized_load">[docs]</a>
    <span class="n">use_ram_optimized_load</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether use disk mapping when memory is not enough.&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.use_flash_attention">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.use_flash_attention">[docs]</a>
    <span class="n">use_flash_attention</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;whether use flash attention layer to reduce GPU memory with higher time cost.&quot;</span><span class="p">)},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.truncate_to_model_max_length">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.truncate_to_model_max_length">[docs]</a>
    <span class="n">truncate_to_model_max_length</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;whether truncate the dataset to model max length.&quot;</span><span class="p">)}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.do_rope_scaling">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.do_rope_scaling">[docs]</a>
    <span class="n">do_rope_scaling</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;whether do ROPE scaling for llama model.&quot;</span>
                <span class="s2">&quot;Linear_scaling credits to the Reddit user /u/kaiokendev.&quot;</span>
                <span class="s2">&quot;https://arxiv.org/abs/2306.15595&quot;</span>
                <span class="s2">&quot;NTK_scaling credits to the Reddit users /u/bloc97 and /u/emozilla.&quot;</span>
                <span class="s2">&quot;https://www.reddit.com/r/LocalLLaMA/comments/14lz7j5/ntkaware_scaled_rope_allows_llama_models_to_have/&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.rope_pi_ratio">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.rope_pi_ratio">[docs]</a>
    <span class="n">rope_pi_ratio</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;the ratio of pi in RoPE scaling.&quot;</span><span class="p">)})</span></div>

<div class="viewcode-block" id="ModelArguments.rope_ntk_ratio">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.rope_ntk_ratio">[docs]</a>
    <span class="n">rope_ntk_ratio</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;the ratio of NTK in RoPE scaling.&quot;</span><span class="p">)})</span></div>

<div class="viewcode-block" id="ModelArguments.use_int8">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.use_int8">[docs]</a>
    <span class="n">use_int8</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;whether to load int8 quantization for inference&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="ModelArguments.load_in_4bit">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.load_in_4bit">[docs]</a>
    <span class="n">load_in_4bit</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;whether to load the model in 4bit&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.model_max_length">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.model_max_length">[docs]</a>
    <span class="n">model_max_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;The maximum length of the model. When not specified, &quot;</span>
                <span class="s2">&quot;will follow the model&#39;s default max length. (i.e., tokenizer.model_max_length)&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.truncation_side">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.truncation_side">[docs]</a>
    <span class="n">truncation_side</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;The side on which the tokenizer should have truncation applied. &quot;</span>
                <span class="s2">&quot;When not specified, will follow the tokenizer&#39;s default truncation strategy. &quot;</span>
                <span class="s2">&quot;(i.e., tokenizer.truncation_side)&quot;</span>
            <span class="p">),</span>
            <span class="s2">&quot;choices&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;left&quot;</span><span class="p">,</span> <span class="s2">&quot;right&quot;</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.padding_side">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.padding_side">[docs]</a>
    <span class="n">padding_side</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;The side on which the tokenizer should have padding applied. &quot;</span>
                <span class="s2">&quot;LMFlow uses right padding by default. When set to `auto`, will &quot;</span>
                <span class="s2">&quot;use padding_side from tokenizer.padding_side.&quot;</span>
            <span class="p">),</span>
            <span class="s2">&quot;choices&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;right&quot;</span><span class="p">,</span> <span class="s2">&quot;left&quot;</span><span class="p">,</span> <span class="s2">&quot;auto&quot;</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="ModelArguments.eos_padding">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.eos_padding">[docs]</a>
    <span class="n">eos_padding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;whether to pad with eos token&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="ModelArguments.ignore_bias_buffers">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.ignore_bias_buffers">[docs]</a>
    <span class="n">ignore_bias_buffers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="c1"># debug argument for distributed training</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;fix for DDP issues with LM bias/mask buffers - invalid scalar type,`inplace operation. See&quot;</span>
            <span class="s2">&quot;https://github.com/huggingface/transformers/issues/22482#issuecomment-1595790992&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="ModelArguments.__post_init__">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.ModelArguments.__post_init__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">__post_init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config_overrides</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name_or_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;--config_overrides can&#39;t be used in combination with --config_name or --model_name_or_path&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_qlora</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_lora</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;use_qlora is set to True, but use_lora is not set to True. Setting use_lora to True.&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">use_lora</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_flash_attention</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">is_flash_attn_available</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">use_flash_attention</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;Flash attention is not available in the current environment. Disabling &quot;</span>
                    <span class="s2">&quot;flash attention. If you want to use flash attention, please install by &quot;</span>
                    <span class="s2">&quot;`pip install -e &#39;.[flash_attn]&#39;`.&quot;</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;Flash attention is not enabled. We recommend enabling flash attention by &quot;</span>
                <span class="s2">&quot;`--use_flash_attention 1` for better performance.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lora_target_modules</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lora_target_modules</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">split_args</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lora_target_modules</span><span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;encoder_decoder&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">arch_type</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;The encoder-decoder model is not fully implemented yet.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bits</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;The argument `bits` is deprecated. Please use `quant_bit` instead.&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">quant_bit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bits</span></div>
</div>



<span class="nd">@dataclass</span>
<div class="viewcode-block" id="VisModelArguments">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.VisModelArguments">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">VisModelArguments</span><span class="p">(</span><span class="n">ModelArguments</span><span class="p">):</span>
<div class="viewcode-block" id="VisModelArguments.low_resource">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.VisModelArguments.low_resource">[docs]</a>
    <span class="n">low_resource</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Use 8 bit and float16 when loading llm&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="VisModelArguments.custom_model">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.VisModelArguments.custom_model">[docs]</a>
    <span class="n">custom_model</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;flag for the model from huggingface or not&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="VisModelArguments.pretrained_language_projection_path">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.VisModelArguments.pretrained_language_projection_path">[docs]</a>
    <span class="n">pretrained_language_projection_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;path for model pretrained_language_projection_path&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="VisModelArguments.custom_vision_model">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.VisModelArguments.custom_vision_model">[docs]</a>
    <span class="n">custom_vision_model</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;flag for the model from huggingface or not&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="VisModelArguments.image_encoder_name_or_path">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.VisModelArguments.image_encoder_name_or_path">[docs]</a>
    <span class="n">image_encoder_name_or_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;The name or path of the image encoder to use.&quot;</span><span class="p">)},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="VisModelArguments.qformer_name_or_path">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.VisModelArguments.qformer_name_or_path">[docs]</a>
    <span class="n">qformer_name_or_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;llm model in multi-modality model&quot;</span><span class="p">)},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="VisModelArguments.llm_model_name_or_path">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.VisModelArguments.llm_model_name_or_path">[docs]</a>
    <span class="n">llm_model_name_or_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;llm model in multi-modality model&quot;</span><span class="p">)},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="VisModelArguments.use_prompt_cache">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.VisModelArguments.use_prompt_cache">[docs]</a>
    <span class="n">use_prompt_cache</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to use prompt cache.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="VisModelArguments.prompt_cache_path">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.VisModelArguments.prompt_cache_path">[docs]</a>
    <span class="n">prompt_cache_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Path to prompt cache.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="VisModelArguments.llava_loading">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.VisModelArguments.llava_loading">[docs]</a>
    <span class="n">llava_loading</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to load module by module from pretrained model.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="VisModelArguments.with_qformer">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.VisModelArguments.with_qformer">[docs]</a>
    <span class="n">with_qformer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to use qformer.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="VisModelArguments.vision_select_layer">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.VisModelArguments.vision_select_layer">[docs]</a>
    <span class="n">vision_select_layer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Which layer to select in vision model.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="VisModelArguments.llava_pretrain_model_path">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.VisModelArguments.llava_pretrain_model_path">[docs]</a>
    <span class="n">llava_pretrain_model_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Path to llava pretrained model.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="VisModelArguments.save_pretrain_model_path">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.VisModelArguments.save_pretrain_model_path">[docs]</a>
    <span class="n">save_pretrain_model_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Path to pretrained model.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>
</div>



<span class="nd">@dataclass</span>
<div class="viewcode-block" id="DatasetArguments">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DatasetArguments">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">DatasetArguments</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Define a class DatasetArguments using the dataclass decorator.</span>
<span class="sd">    The class contains several optional parameters that can be used to configure a dataset for a language model.</span>


<span class="sd">    dataset_path : str</span>
<span class="sd">        a string representing the path of the dataset to use.</span>

<span class="sd">    dataset_name : str</span>
<span class="sd">        a string representing the name of the dataset to use. The default value is &quot;customized&quot;.</span>

<span class="sd">    is_custom_dataset : bool</span>
<span class="sd">        a boolean indicating whether to use custom data. The default value is False.</span>

<span class="sd">    customized_cache_dir : str</span>
<span class="sd">        a string representing the path to the directory where customized dataset caches will be stored.</span>

<span class="sd">    dataset_config_name : str</span>
<span class="sd">        a string representing the configuration name of the dataset to use (via the datasets library).</span>

<span class="sd">    train_file : str</span>
<span class="sd">        a string representing the path to the input training data file (a text file).</span>

<span class="sd">    validation_file : str</span>
<span class="sd">        a string representing the path to the input evaluation data file to evaluate the perplexity on (a text file).</span>

<span class="sd">    max_train_samples : int</span>
<span class="sd">        an integer indicating the maximum number of training examples to use for debugging or quicker training.</span>
<span class="sd">        If set, the training dataset will be truncated to this number.</span>

<span class="sd">    max_eval_samples: int</span>
<span class="sd">        an integer indicating the maximum number of evaluation examples to use for debugging or quicker training.</span>
<span class="sd">        If set, the evaluation dataset will be truncated to this number.</span>

<span class="sd">    streaming : bool</span>
<span class="sd">        a boolean indicating whether to enable streaming mode.</span>

<span class="sd">    block_size: int</span>
<span class="sd">        an integer indicating the optional input sequence length after tokenization. The training dataset will be</span>
<span class="sd">        truncated in blocks of this size for training.</span>

<span class="sd">    train_on_prompt: bool</span>
<span class="sd">        a boolean indicating whether to train on prompt for conversation datasets such as ShareGPT.</span>

<span class="sd">    conversation_template: str</span>
<span class="sd">        a string representing the template for conversation datasets.</span>

<span class="sd">    dataset_cache_dir: str</span>
<span class="sd">        a string representing the path to the dataset cache directory. Useful when the default cache dir</span>
<span class="sd">        (`~/.cache/huggingface/datasets`) has limited space.</span>

<span class="sd">    The class also includes some additional parameters that can be used to configure the dataset further, such as</span>
<span class="sd">    `overwrite_cache`, `validation_split_percentage`, `preprocessing_num_workers`, `disable_group_texts`,</span>
<span class="sd">    `demo_example_in_prompt`, `explanation_in_prompt`, `keep_linebreaks`, and `prompt_structure`.</span>

<span class="sd">    The field function is used to set default values and provide help messages for each parameter. The Optional type</span>
<span class="sd">    hint is used to indicate that a parameter is optional. The metadata argument is used to provide additional</span>
<span class="sd">    information about each parameter, such as a help message.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="DatasetArguments.dataset_path">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DatasetArguments.dataset_path">[docs]</a>
    <span class="n">dataset_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The path of the dataset to use.&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="DatasetArguments.dataset_name">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DatasetArguments.dataset_name">[docs]</a>
    <span class="n">dataset_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="s2">&quot;customized&quot;</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s1">&#39;Should be &quot;customized&quot;&#39;</span><span class="p">})</span></div>

<div class="viewcode-block" id="DatasetArguments.is_custom_dataset">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DatasetArguments.is_custom_dataset">[docs]</a>
    <span class="n">is_custom_dataset</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;whether to use custom data&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="DatasetArguments.customized_cache_dir">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DatasetArguments.customized_cache_dir">[docs]</a>
    <span class="n">customized_cache_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;.cache/llm-ft/datasets&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Where do you want to store the customized dataset caches&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="DatasetArguments.dataset_config_name">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DatasetArguments.dataset_config_name">[docs]</a>
    <span class="n">dataset_config_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The configuration name of the dataset to use (via the datasets library).&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="DatasetArguments.train_file">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DatasetArguments.train_file">[docs]</a>
    <span class="n">train_file</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The input training data file (a text file).&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="DatasetArguments.validation_file">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DatasetArguments.validation_file">[docs]</a>
    <span class="n">validation_file</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;An optional input evaluation data file to evaluate the perplexity on (a text file).&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="DatasetArguments.max_train_samples">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DatasetArguments.max_train_samples">[docs]</a>
    <span class="n">max_train_samples</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;For debugging purposes or quicker training, truncate the number of training examples to this &quot;</span>
                <span class="s2">&quot;value if set.&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="DatasetArguments.max_eval_samples">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DatasetArguments.max_eval_samples">[docs]</a>
    <span class="n">max_eval_samples</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">1e10</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;For debugging purposes or quicker training, truncate the number of evaluation examples to this &quot;</span>
                <span class="s2">&quot;value if set.&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="DatasetArguments.streaming">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DatasetArguments.streaming">[docs]</a>
    <span class="n">streaming</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Enable streaming mode&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="DatasetArguments.block_size">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DatasetArguments.block_size">[docs]</a>
    <span class="n">block_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;Optional input sequence length after tokenization. &quot;</span>
                <span class="s2">&quot;The training dataset will be truncated in block of this size for training. &quot;</span>
                <span class="s2">&quot;Default to the model max input length for single sentence inputs (take into account special tokens).&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="DatasetArguments.overwrite_cache">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DatasetArguments.overwrite_cache">[docs]</a>
    <span class="n">overwrite_cache</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Overwrite the cached training and evaluation sets&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="DatasetArguments.validation_split_percentage">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DatasetArguments.validation_split_percentage">[docs]</a>
    <span class="n">validation_split_percentage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The percentage of the train set used as validation set in case there&#39;s no validation split&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="DatasetArguments.preprocessing_num_workers">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DatasetArguments.preprocessing_num_workers">[docs]</a>
    <span class="n">preprocessing_num_workers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The number of processes to use for the preprocessing.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="DatasetArguments.group_texts_batch_size">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DatasetArguments.group_texts_batch_size">[docs]</a>
    <span class="n">group_texts_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;Number of samples that will be grouped together to go though&quot;</span>
                <span class="s2">&quot; `group_texts` operation. See `--disable_group_texts` for&quot;</span>
                <span class="s2">&quot; detailed explanation of this operation.&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="DatasetArguments.disable_group_texts">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DatasetArguments.disable_group_texts">[docs]</a>
    <span class="n">disable_group_texts</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;Whether we disable group of original samples together to&quot;</span>
                <span class="s2">&quot; generate sample sequences of length `block_size`&quot;</span>
                <span class="s2">&quot; By Default, it is True, which means the long samples&quot;</span>
                <span class="s2">&quot; are truncated to `block_size` tokens&quot;</span>
                <span class="s2">&quot; and short samples are padded to `block_size` tokens.&quot;</span>
                <span class="s2">&quot; If set to False, we group every 1000 tokenized&quot;</span>
                <span class="s2">&quot; sequences together, divide them into&quot;</span>
                <span class="s2">&quot; [</span><span class="si">{total_num_tokens}</span><span class="s2"> / </span><span class="si">{block_size}</span><span class="s2">] sequences,&quot;</span>
                <span class="s2">&quot; each with `block_size` tokens&quot;</span>
                <span class="s2">&quot; (the remaining tokens are ommited.&quot;</span>
                <span class="s2">&quot; This group text behavior is useful&quot;</span>
                <span class="s2">&quot; for continual pretrain or pretrain.&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="DatasetArguments.keep_linebreaks">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DatasetArguments.keep_linebreaks">[docs]</a>
    <span class="n">keep_linebreaks</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to keep line breaks when using TXT files or not.&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="DatasetArguments.test_file">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DatasetArguments.test_file">[docs]</a>
    <span class="n">test_file</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Evaluation File Path&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="DatasetArguments.train_on_prompt">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DatasetArguments.train_on_prompt">[docs]</a>
    <span class="n">train_on_prompt</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to train on prompt for conversation datasets such as ShareGPT.&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="DatasetArguments.conversation_template">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DatasetArguments.conversation_template">[docs]</a>
    <span class="n">conversation_template</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The template for conversation datasets.&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="DatasetArguments.dataset_cache_dir">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DatasetArguments.dataset_cache_dir">[docs]</a>
    <span class="n">dataset_cache_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;The path to the dataset cache directory. Useful when the &quot;</span>
                <span class="s2">&quot;default cache dir (`~/.cache/huggingface/datasets`) has limited space.&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="DatasetArguments.calculate_dataset_stats">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DatasetArguments.calculate_dataset_stats">[docs]</a>
    <span class="n">calculate_dataset_stats</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;Whether to calculate the dataset statistics, including the number of samples, &quot;</span>
                <span class="s2">&quot;the average length of samples, total tokens, etc.&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="DatasetArguments.__post_init__">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DatasetArguments.__post_init__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">__post_init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">streaming</span><span class="p">:</span>
            <span class="n">require_version</span><span class="p">(</span><span class="s2">&quot;datasets&gt;=2.0.0&quot;</span><span class="p">,</span> <span class="s2">&quot;The streaming feature requires `datasets&gt;=2.0.0`&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_name</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_file</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">validation_file</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Need either a dataset name or a training/validation file.&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_file</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">extension</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_file</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="k">assert</span> <span class="n">extension</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;csv&quot;</span><span class="p">,</span> <span class="s2">&quot;json&quot;</span><span class="p">,</span> <span class="s2">&quot;txt&quot;</span><span class="p">],</span> <span class="s2">&quot;`train_file` should be a csv, a json or a txt file.&quot;</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">validation_file</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">extension</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">validation_file</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="k">assert</span> <span class="n">extension</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;csv&quot;</span><span class="p">,</span> <span class="s2">&quot;json&quot;</span><span class="p">,</span> <span class="s2">&quot;txt&quot;</span><span class="p">],</span> <span class="s2">&quot;`validation_file` should be a csv, a json or a txt file.&quot;</span></div>
</div>



<span class="nd">@dataclass</span>
<div class="viewcode-block" id="MultiModalDatasetArguments">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.MultiModalDatasetArguments">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">MultiModalDatasetArguments</span><span class="p">(</span><span class="n">DatasetArguments</span><span class="p">):</span>
<div class="viewcode-block" id="MultiModalDatasetArguments.image_folder">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.MultiModalDatasetArguments.image_folder">[docs]</a>
    <span class="n">image_folder</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The folder of the image file.&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="MultiModalDatasetArguments.image_aspect_ratio">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.MultiModalDatasetArguments.image_aspect_ratio">[docs]</a>
    <span class="n">image_aspect_ratio</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="s2">&quot;pad&quot;</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The ratio type&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="MultiModalDatasetArguments.is_multimodal">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.MultiModalDatasetArguments.is_multimodal">[docs]</a>
    <span class="n">is_multimodal</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Flag for the modality type.&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="MultiModalDatasetArguments.use_image_start_end">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.MultiModalDatasetArguments.use_image_start_end">[docs]</a>
    <span class="n">use_image_start_end</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Flag for the modality type.&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="MultiModalDatasetArguments.sep_style">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.MultiModalDatasetArguments.sep_style">[docs]</a>
    <span class="n">sep_style</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="s2">&quot;plain&quot;</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Sep style in multi_modality dataset.&quot;</span><span class="p">})</span></div>
</div>



<span class="nd">@dataclass</span>
<div class="viewcode-block" id="FinetunerArguments">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.FinetunerArguments">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">FinetunerArguments</span><span class="p">(</span><span class="n">TrainingArguments</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Adapt transformers.TrainingArguments</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="FinetunerArguments.eval_dataset_path">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.FinetunerArguments.eval_dataset_path">[docs]</a>
    <span class="n">eval_dataset_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The path of the eval dataset to use.&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="FinetunerArguments.remove_unused_columns">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.FinetunerArguments.remove_unused_columns">[docs]</a>
    <span class="n">remove_unused_columns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;whether to remove the unused columns in collate fn&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="FinetunerArguments.finetune_part">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.FinetunerArguments.finetune_part">[docs]</a>
    <span class="n">finetune_part</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="s2">&quot;language_projection&quot;</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the module to finetune.&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="FinetunerArguments.save_language_projection">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.FinetunerArguments.save_language_projection">[docs]</a>
    <span class="n">save_language_projection</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;whether to save language projection layer in multi-modal models.&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="FinetunerArguments.use_lisa">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.FinetunerArguments.use_lisa">[docs]</a>
    <span class="n">use_lisa</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;whether to use LISA training strategy.&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="FinetunerArguments.lisa_activated_layers">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.FinetunerArguments.lisa_activated_layers">[docs]</a>
    <span class="n">lisa_activated_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the number of activated layers in LISA.&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="FinetunerArguments.lisa_interval_steps">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.FinetunerArguments.lisa_interval_steps">[docs]</a>
    <span class="n">lisa_interval_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the number of steps in each freezing interval of LISA, i.e. the selected unfreezed layers &quot;</span>
            <span class="s2">&quot;are randomly switched every </span><span class="si">{lisa_interval_steps}</span><span class="s2"> steps.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="FinetunerArguments.lisa_layers_attribute">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.FinetunerArguments.lisa_layers_attribute">[docs]</a>
    <span class="n">lisa_layers_attribute</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;model.model.layers&quot;</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;where the layer attribute stores, e.g. model.model.layers&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="FinetunerArguments.use_customized_optim">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.FinetunerArguments.use_customized_optim">[docs]</a>
    <span class="n">use_customized_optim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;whether to use customized optimizers.&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="FinetunerArguments.customized_optim">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.FinetunerArguments.customized_optim">[docs]</a>
    <span class="n">customized_optim</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="s2">&quot;sign_sgd&quot;</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;name of the customized optimizer.&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="FinetunerArguments.customized_optim_args">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.FinetunerArguments.customized_optim_args">[docs]</a>
    <span class="n">customized_optim_args</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;optional arguments that are supplied.&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="FinetunerArguments.optim_dummy_beta1">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.FinetunerArguments.optim_dummy_beta1">[docs]</a>
    <span class="n">optim_dummy_beta1</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;A useless argument for dummy optimizer, just for tutorial&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="FinetunerArguments.optim_dummy_beta2">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.FinetunerArguments.optim_dummy_beta2">[docs]</a>
    <span class="n">optim_dummy_beta2</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;A useless argument for dummy optimizer, just for tutorial&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="FinetunerArguments.optim_adam_beta1">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.FinetunerArguments.optim_adam_beta1">[docs]</a>
    <span class="n">optim_adam_beta1</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Coefficient used for computing running averages of gradient&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="FinetunerArguments.optim_adam_beta2">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.FinetunerArguments.optim_adam_beta2">[docs]</a>
    <span class="n">optim_adam_beta2</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Coefficient used for computing running averages of squared gradient&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="FinetunerArguments.optim_beta1">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.FinetunerArguments.optim_beta1">[docs]</a>
    <span class="n">optim_beta1</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Coefficient used for computing running averages of gradient&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="FinetunerArguments.optim_beta2">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.FinetunerArguments.optim_beta2">[docs]</a>
    <span class="n">optim_beta2</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Coefficient used for computing running averages of squared gradient&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="FinetunerArguments.optim_beta3">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.FinetunerArguments.optim_beta3">[docs]</a>
    <span class="n">optim_beta3</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Coefficient used for computing running averages of gradient&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="FinetunerArguments.optim_momentum">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.FinetunerArguments.optim_momentum">[docs]</a>
    <span class="n">optim_momentum</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Coefficient used for the momentum term in optimizers like SGD with momentum&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="FinetunerArguments.optim_weight_decay">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.FinetunerArguments.optim_weight_decay">[docs]</a>
    <span class="n">optim_weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Weight decay (L2 penalty) added to the loss to prevent overfitting&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>
</div>



<span class="nd">@dataclass</span>
<div class="viewcode-block" id="RewardModelTunerArguments">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.RewardModelTunerArguments">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">RewardModelTunerArguments</span><span class="p">(</span><span class="n">FinetunerArguments</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Arguments for reward modeling.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">pass</span></div>



<span class="nd">@dataclass</span>
<div class="viewcode-block" id="EvaluatorArguments">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.EvaluatorArguments">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">EvaluatorArguments</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Define a class EvaluatorArguments using the dataclass decorator. The class contains several optional</span>
<span class="sd">    parameters that can be used to configure a evaluator.</span>

<span class="sd">    local_rank : str</span>
<span class="sd">        For distributed training: local_rank</span>

<span class="sd">    random_shuffle : bool</span>

<span class="sd">    use_wandb : bool</span>

<span class="sd">    random_seed : int, default = 1</span>

<span class="sd">    output_dir : str, default = &#39;./output_dir&#39;,</span>

<span class="sd">    mixed_precision : str, choice from [&quot;bf16&quot;,&quot;fp16&quot;].</span>
<span class="sd">        mixed precision mode, whether to use bf16 or fp16</span>

<span class="sd">    deepspeed :</span>
<span class="sd">        Enable deepspeed and pass the path to deepspeed json config file (e.g. ds_config.json) or an already</span>
<span class="sd">        loaded json file as a dict</span>

<span class="sd">    temperature : float</span>
<span class="sd">        An argument of model.generate in huggingface to control the diversity of generation.</span>

<span class="sd">    repetition_penalty : float</span>
<span class="sd">        An argument of model.generate in huggingface to penalize repetitions.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="EvaluatorArguments.local_rank">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.EvaluatorArguments.local_rank">[docs]</a>
    <span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;For distributed training: local_rank&quot;</span><span class="p">})</span></div>


<div class="viewcode-block" id="EvaluatorArguments.random_shuffle">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.EvaluatorArguments.random_shuffle">[docs]</a>
    <span class="n">random_shuffle</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;&quot;</span><span class="p">})</span></div>


<div class="viewcode-block" id="EvaluatorArguments.use_wandb">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.EvaluatorArguments.use_wandb">[docs]</a>
    <span class="n">use_wandb</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;When this flag is True, wandb will be enabled&quot;</span><span class="p">)},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="EvaluatorArguments.random_seed">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.EvaluatorArguments.random_seed">[docs]</a>
    <span class="n">random_seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;used to set random seed&quot;</span><span class="p">)},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="EvaluatorArguments.output_dir">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.EvaluatorArguments.output_dir">[docs]</a>
    <span class="n">output_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;./output_dir&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Output path for the inferenced results&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="EvaluatorArguments.mixed_precision">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.EvaluatorArguments.mixed_precision">[docs]</a>
    <span class="n">mixed_precision</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;bf16&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;mixed precision mode, whether to use bf16 or fp16&quot;</span><span class="p">),</span>
            <span class="s2">&quot;choices&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;bf16&quot;</span><span class="p">,</span> <span class="s2">&quot;fp16&quot;</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="EvaluatorArguments.deepspeed">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.EvaluatorArguments.deepspeed">[docs]</a>
    <span class="n">deepspeed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;Enable deepspeed and pass the path to deepspeed json config file (e.g. ds_config.json) or an already&quot;</span>
                <span class="s2">&quot; loaded json file as a dict&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="EvaluatorArguments.answer_type">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.EvaluatorArguments.answer_type">[docs]</a>
    <span class="n">answer_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;text&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;Question type for answer extraction from the decoder output.&quot;</span>
                <span class="s2">&quot; Supported types: </span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s1">&#39;   1) &quot;multiple_choice&quot;, e.g. A, B, C, D, ...</span><span class="se">\n</span><span class="s1">&#39;</span>
                <span class="s1">&#39;   2) &quot;binary_choice&quot;, e.g. yes, no, maybe</span><span class="se">\n</span><span class="s1">&#39;</span>
                <span class="s1">&#39;   3) &quot;math&quot;, e.g. 1.0, -3.52</span><span class="se">\n</span><span class="s1">&#39;</span>
                <span class="s1">&#39;   4) &quot;text&quot;, e.g. &quot;I think that it is okay&quot;</span><span class="se">\n</span><span class="s1">&#39;</span>
                <span class="s2">&quot;   5) Special treatment for several datasets</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s1">&#39;     - &quot;gsm8k&quot;</span><span class="se">\n</span><span class="s1">&#39;</span>
                <span class="s1">&#39;     - &quot;svamp&quot;</span><span class="se">\n</span><span class="s1">&#39;</span>
                <span class="s1">&#39;     - &quot;asdiv&quot;</span><span class="se">\n</span><span class="s1">&#39;</span>
                <span class="s1">&#39;     - &quot;addsub&quot;</span><span class="se">\n</span><span class="s1">&#39;</span>
                <span class="s1">&#39;     - &quot;singleeq&quot;</span><span class="se">\n</span><span class="s1">&#39;</span>
                <span class="s1">&#39;     - &quot;multiarith&quot;</span><span class="se">\n</span><span class="s1">&#39;</span>
                <span class="s1">&#39;     - &quot;aqua&quot;</span><span class="se">\n</span><span class="s1">&#39;</span>
                <span class="s1">&#39;     - &quot;csqa&quot;</span><span class="se">\n</span><span class="s1">&#39;</span>
                <span class="s1">&#39;     - &quot;strategyqa&quot;</span><span class="se">\n</span><span class="s1">&#39;</span>
                <span class="s1">&#39;     - &quot;pubmedqa&quot;</span><span class="se">\n</span><span class="s1">&#39;</span>
                <span class="s1">&#39;     - &quot;medmcqa&quot;</span><span class="se">\n</span><span class="s1">&#39;</span>
                <span class="s1">&#39;     - &quot;usmle&quot;</span><span class="se">\n</span><span class="s1">&#39;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="EvaluatorArguments.prompt_structure">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.EvaluatorArguments.prompt_structure">[docs]</a>
    <span class="n">prompt_structure</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">{input}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;Prompt structure to facilitate prompt engineering during&quot;</span>
                <span class="s2">&quot; inference. The model will receive&quot;</span>
                <span class="s2">&quot; `prompt_structure.format(input=input)` as its input.&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="EvaluatorArguments.evaluate_block_size">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.EvaluatorArguments.evaluate_block_size">[docs]</a>
    <span class="n">evaluate_block_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;the model will have at least block_size tokens for context when calculating the &quot;</span>
                <span class="s2">&quot;conditional likelihood of any one token (provided there are block_size preceding &quot;</span>
                <span class="s2">&quot;tokens available to condition on)&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="EvaluatorArguments.metric">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.EvaluatorArguments.metric">[docs]</a>
    <span class="n">metric</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the metric the model will be evaluated on&quot;</span><span class="p">,</span>
            <span class="s2">&quot;choices&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;ppl&quot;</span><span class="p">,</span> <span class="s2">&quot;perplexity&quot;</span><span class="p">,</span> <span class="s2">&quot;acc&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;neg_log_likelihood&quot;</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="EvaluatorArguments.inference_batch_size_per_device">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.EvaluatorArguments.inference_batch_size_per_device">[docs]</a>
    <span class="n">inference_batch_size_per_device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;every device will infer </span><span class="si">{inference_batch_size_per_device}</span><span class="s2">&quot;</span>
                <span class="s2">&quot; samples in parallel. The inferred results will be concatenaed&quot;</span>
                <span class="s2">&quot; with inputs and attach a reward.&quot;</span>
            <span class="p">),</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="EvaluatorArguments.use_accelerator_for_evaluator">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.EvaluatorArguments.use_accelerator_for_evaluator">[docs]</a>
    <span class="n">use_accelerator_for_evaluator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;[Deprecated] Whether to use Huggingface Accelerator instead of Deepspeed&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="EvaluatorArguments.temperature">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.EvaluatorArguments.temperature">[docs]</a>
    <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Temperature during inference.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="EvaluatorArguments.repetition_penalty">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.EvaluatorArguments.repetition_penalty">[docs]</a>
    <span class="n">repetition_penalty</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Repetition_penalty during inference.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="EvaluatorArguments.max_new_tokens">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.EvaluatorArguments.max_new_tokens">[docs]</a>
    <span class="n">max_new_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Maximum length during inference.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="EvaluatorArguments.minibatch_size">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.EvaluatorArguments.minibatch_size">[docs]</a>
    <span class="n">minibatch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Mini batch size during evaluation.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="EvaluatorArguments.__post_init__">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.EvaluatorArguments.__post_init__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">__post_init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_accelerator_for_evaluator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;You&#39;ve specified `use_accelerator_for_evaluator`. This argument is deprecated. &quot;</span>
                <span class="s2">&quot;It will not take effect and will be removed in a future version, &quot;</span>
                <span class="s2">&quot;since LMFlow now can automatically detect whether is in Accelerate or Deepspeed environment.&quot;</span>
            <span class="p">)</span></div>
</div>



<span class="nd">@dataclass</span>
<div class="viewcode-block" id="InferencerArguments">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">InferencerArguments</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Define a class InferencerArguments using the dataclass decorator. The class contains several optional</span>
<span class="sd">    parameters that can be used to configure a inferencer.</span>

<span class="sd">    local_rank : str</span>
<span class="sd">        For distributed training: local_rank</span>
<span class="sd">    random_seed : int, default = 1</span>
<span class="sd">    inference_batch_size : int, default = 1</span>
<span class="sd">    deepspeed :</span>
<span class="sd">        Enable deepspeed and pass the path to deepspeed json config file (e.g. ds_config.json) or an already</span>
<span class="sd">        loaded json file as a dict</span>
<span class="sd">    mixed_precision : str, choice from [&quot;bf16&quot;,&quot;fp16&quot;].</span>
<span class="sd">        mixed precision mode, whether to use bf16 or fp16</span>
<span class="sd">    temperature : float</span>
<span class="sd">        An argument of model.generate in huggingface to control the diversity of generation.</span>
<span class="sd">    repetition_penalty : float</span>
<span class="sd">        An argument of model.generate in huggingface to penalize repetitions.</span>
<span class="sd">    use_beam_search : Optional[bool]</span>
<span class="sd">        Whether to use beam search during inference, By default False.</span>
<span class="sd">    num_output_sequences : Optional[int]</span>
<span class="sd">        Number of output sequences to return for the given prompt,</span>
<span class="sd">        currently only used in vllm inference, By default 8.</span>
<span class="sd">    top_p : Optional[float]</span>
<span class="sd">        top_p for sampling, By default 1.0.</span>
<span class="sd">    top_k : Optional[int]</span>
<span class="sd">        top_k for sampling, By default -1 (no top_k).</span>
<span class="sd">    additional_stop_token_ids : Optional[list[int]]</span>
<span class="sd">        the ids of the end of sentence tokens, By default [].</span>
<span class="sd">    apply_chat_template : Optional[bool]</span>
<span class="sd">        Whether to apply chat template, By default True.</span>
<span class="sd">    save_results : Optional[bool]</span>
<span class="sd">        Whether to save inference results, By default False.</span>
<span class="sd">    results_path : Optional[str]</span>
<span class="sd">        The **json file** path of inference results, By default None.</span>
<span class="sd">    enable_decode_inference_result : Optional[bool]</span>
<span class="sd">        Whether to detokenize the inference results.</span>

<span class="sd">        NOTE: For iterative align pipelines, whether to detokenize depends on</span>
<span class="sd">        the homogeneity of the policy model and the reward model</span>
<span class="sd">        (i.e., if they have the same tokenizer).</span>
<span class="sd">    use_vllm: bool, optional</span>
<span class="sd">        Whether to use VLLM for inference, By default False.</span>
<span class="sd">    vllm_tensor_parallel_size: int, optional</span>
<span class="sd">        The tensor parallel size for VLLM inference.</span>
<span class="sd">    vllm_gpu_memory_utilization: float, optional</span>
<span class="sd">        The GPU memory utilization for VLLM inference. The proportion of GPU</span>
<span class="sd">        memory (per GPU) to use for VLLM inference.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="InferencerArguments.device">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.device">[docs]</a>
    <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;gpu&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;device of chatbot&quot;</span><span class="p">,</span>
            <span class="s2">&quot;choices&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;gpu&quot;</span><span class="p">,</span> <span class="s2">&quot;cpu&quot;</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="InferencerArguments.local_rank">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.local_rank">[docs]</a>
    <span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;For distributed training: local_rank&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="InferencerArguments.inference_batch_size">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.inference_batch_size">[docs]</a>
    <span class="n">inference_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;batch size for inference&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="InferencerArguments.vllm_inference_batch_size">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.vllm_inference_batch_size">[docs]</a>
    <span class="n">vllm_inference_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The batch size for VLLM inference.&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="InferencerArguments.temperature">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.temperature">[docs]</a>
    <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Temperature during inference.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="InferencerArguments.repetition_penalty">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.repetition_penalty">[docs]</a>
    <span class="n">repetition_penalty</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Repetition_penalty during inference.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="InferencerArguments.max_new_tokens">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.max_new_tokens">[docs]</a>
    <span class="n">max_new_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Maximum length during inference.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="InferencerArguments.random_seed">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.random_seed">[docs]</a>
    <span class="n">random_seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;used to set random seed&quot;</span><span class="p">)},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="InferencerArguments.deepspeed">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.deepspeed">[docs]</a>
    <span class="n">deepspeed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;Enable deepspeed and pass the path to deepspeed json config file (e.g. ds_config.json) or an already&quot;</span>
                <span class="s2">&quot; loaded json file as a dict&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="InferencerArguments.mixed_precision">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.mixed_precision">[docs]</a>
    <span class="n">mixed_precision</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;bf16&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;mixed precision mode, whether to use bf16 or fp16&quot;</span><span class="p">),</span>
            <span class="s2">&quot;choices&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;bf16&quot;</span><span class="p">,</span> <span class="s2">&quot;fp16&quot;</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="InferencerArguments.do_sample">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.do_sample">[docs]</a>
    <span class="n">do_sample</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;whether turn on true random sampling during inference.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="InferencerArguments.return_logprob">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.return_logprob">[docs]</a>
    <span class="n">return_logprob</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;whether to return log probability during inference.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="InferencerArguments.use_accelerator">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.use_accelerator">[docs]</a>
    <span class="n">use_accelerator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;[Deprecated] Whether to use Huggingface Accelerator instead of Deepspeed&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="InferencerArguments.use_beam_search">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.use_beam_search">[docs]</a>
    <span class="n">use_beam_search</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;whether to use beam search during inference.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="InferencerArguments.num_output_sequences">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.num_output_sequences">[docs]</a>
    <span class="n">num_output_sequences</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;number of output sequences to return for the given prompt, currently only used in vllm inference.&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="InferencerArguments.top_p">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.top_p">[docs]</a>
    <span class="n">top_p</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;top_p for sampling.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="InferencerArguments.top_k">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.top_k">[docs]</a>
    <span class="n">top_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;top_k for sampling.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="InferencerArguments.additional_stop_token_ids">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.additional_stop_token_ids">[docs]</a>
    <span class="n">additional_stop_token_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default_factory</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="p">[],</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the ids of the end of sentence tokens&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="InferencerArguments.apply_chat_template">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.apply_chat_template">[docs]</a>
    <span class="n">apply_chat_template</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;whether to apply chat template&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="InferencerArguments.enable_decode_inference_result">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.enable_decode_inference_result">[docs]</a>
    <span class="n">enable_decode_inference_result</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to decode the inference results.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="InferencerArguments.tensor_parallel_size">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.tensor_parallel_size">[docs]</a>
    <span class="n">tensor_parallel_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The tp size for distributed (multi-instance) inference.&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="InferencerArguments.enable_distributed_inference">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.enable_distributed_inference">[docs]</a>
    <span class="n">enable_distributed_inference</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to use multi-instance VLLM inference.&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="InferencerArguments.distributed_inference_num_instances">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.distributed_inference_num_instances">[docs]</a>
    <span class="n">distributed_inference_num_instances</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The number of instances for multi-instance VLLM inference.&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>


    <span class="c1"># vllm inference args</span>
<div class="viewcode-block" id="InferencerArguments.use_vllm">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.use_vllm">[docs]</a>
    <span class="n">use_vllm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to use VLLM for inference, By default None. Deprecated, use inference_engine instead.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="InferencerArguments.vllm_tensor_parallel_size">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.vllm_tensor_parallel_size">[docs]</a>
    <span class="n">vllm_tensor_parallel_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;The tensor parallel size for VLLM inference. Deprecated, use inference_tensor_parallel_size instead.&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="InferencerArguments.vllm_gpu_memory_utilization">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.vllm_gpu_memory_utilization">[docs]</a>
    <span class="n">vllm_gpu_memory_utilization</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;The GPU memory utilization for VLLM inference. &quot;</span>
                <span class="s2">&quot;Deprecated, use inference_gpu_memory_utilization instead.&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span></div>


    <span class="c1"># inference engine args</span>
<div class="viewcode-block" id="InferencerArguments.inference_engine">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.inference_engine">[docs]</a>
    <span class="n">inference_engine</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;huggingface&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The inference engine to use, by default huggingface.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;choices&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;huggingface&quot;</span><span class="p">,</span> <span class="s2">&quot;vllm&quot;</span><span class="p">,</span> <span class="s2">&quot;sglang&quot;</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="InferencerArguments.inference_tensor_parallel_size">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.inference_tensor_parallel_size">[docs]</a>
    <span class="n">inference_tensor_parallel_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The tensor parallel size for inference.&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="InferencerArguments.inference_gpu_memory_utilization">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.inference_gpu_memory_utilization">[docs]</a>
    <span class="n">inference_gpu_memory_utilization</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The GPU memory utilization for inference.&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="InferencerArguments.enable_deterministic_inference">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.enable_deterministic_inference">[docs]</a>
    <span class="n">enable_deterministic_inference</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to enable deterministic inference. Only supported for SGLang inference engine currently.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="InferencerArguments.attention_backend">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.attention_backend">[docs]</a>
    <span class="n">attention_backend</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;The attention backend to use. Only supported for SGLang inference engine currently. &quot;</span>
                <span class="s2">&quot;Please leave it as None to let SGLang automatically choose if you&#39;re not sure.&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span></div>


    <span class="c1"># Args for result saving</span>
<div class="viewcode-block" id="InferencerArguments.save_results">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.save_results">[docs]</a>
    <span class="n">save_results</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to save results.&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="InferencerArguments.results_path">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.results_path">[docs]</a>
    <span class="n">results_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The path of results.&quot;</span><span class="p">})</span></div>

    
<div class="viewcode-block" id="InferencerArguments.save_inference_results">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.save_inference_results">[docs]</a>
    <span class="n">save_inference_results</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to save inference results.&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="InferencerArguments.inference_results_path">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.inference_results_path">[docs]</a>
    <span class="n">inference_results_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The path of inference results.&quot;</span><span class="p">})</span></div>


<div class="viewcode-block" id="InferencerArguments.__post_init__">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.InferencerArguments.__post_init__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">__post_init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_accelerator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;You&#39;ve specified `use_accelerator`. This argument is deprecated. &quot;</span>
                <span class="s2">&quot;It will not take effect and will be removed in a future version, &quot;</span>
                <span class="s2">&quot;since LMFlow now can automatically detect whether is in Accelerate or Deepspeed environment.&quot;</span>
            <span class="p">)</span>
            
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_results</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;`save_results` is deprecated and will be removed in a future version. Please use `save_inference_results` instead.&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save_inference_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_results</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">results_path</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;`results_path` is deprecated and will be removed in a future version. Please use `inference_results_path` instead.&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inference_results_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">results_path</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_inference_results</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_results_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Need to specify inference_results_path when save_inference_results is True.&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_results_path</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.json&quot;</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The inference_results_path must be a json file.&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">Path</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_results_path</span><span class="p">)</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_vllm</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;Inference engine is set to vllm. You&#39;ve specified `use_vllm`. This argument is deprecated and &quot;</span>
                <span class="s2">&quot;will be removed in a future version. Please use `inference_engine` instead.&quot;</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine</span> <span class="o">=</span> <span class="s2">&quot;vllm&quot;</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">vllm_tensor_parallel_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;You&#39;ve specified `vllm_tensor_parallel_size`. This argument is deprecated and &quot;</span>
                    <span class="s2">&quot;will be removed in a future version. Please use `inference_tensor_parallel_size` instead.&quot;</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">inference_tensor_parallel_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vllm_tensor_parallel_size</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">vllm_gpu_memory_utilization</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;You&#39;ve specified `vllm_gpu_memory_utilization`. This argument is deprecated and &quot;</span>
                    <span class="s2">&quot;will be removed in a future version. Please use `inference_gpu_memory_utilization` instead.&quot;</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">inference_gpu_memory_utilization</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vllm_gpu_memory_utilization</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine</span> <span class="o">!=</span> <span class="s2">&quot;sglang&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_logprob</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;`return_logprob` is only supported for SGLang inference engine currently. &quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine</span> <span class="o">==</span> <span class="s2">&quot;sglang&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">enable_deterministic_inference</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_backend</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">attention_backend</span> <span class="o">=</span> <span class="s2">&quot;fa3&quot;</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                        <span class="s2">&quot;`enable_deterministic_inference` is enabled, but `attention_backend` is not specified. &quot;</span>
                        <span class="s2">&quot;Using `fa3` as the attention backend by default.&quot;</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_backend</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;fa3&quot;</span><span class="p">,</span> <span class="s2">&quot;flashinfer&quot;</span><span class="p">,</span> <span class="s2">&quot;triton&quot;</span><span class="p">],</span> <span class="p">(</span>
                        <span class="s2">&quot;Invalid attention backend. Please choose from &#39;fa3&#39;, &#39;flashinfer&#39;, or &#39;triton&#39;.&quot;</span>
                    <span class="p">)</span></div>
</div>



<span class="nd">@dataclass</span>
<div class="viewcode-block" id="RaftAlignerArguments">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.RaftAlignerArguments">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">RaftAlignerArguments</span><span class="p">(</span><span class="n">TrainingArguments</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Define a class RaftAlignerArguments to configure raft aligner.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="RaftAlignerArguments.output_reward_path">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.RaftAlignerArguments.output_reward_path">[docs]</a>
    <span class="n">output_reward_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;tmp/raft_aligner/&quot;</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The path of output rewards.&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="RaftAlignerArguments.output_min_length">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.RaftAlignerArguments.output_min_length">[docs]</a>
    <span class="n">output_min_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;minimum length of the output token sequence generated from model given an input.&quot;</span><span class="p">),</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="RaftAlignerArguments.output_max_length">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.RaftAlignerArguments.output_max_length">[docs]</a>
    <span class="n">output_max_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;maximum length of the output token sequence generated from model given an output.&quot;</span><span class="p">),</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="RaftAlignerArguments.num_raft_iteration">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.RaftAlignerArguments.num_raft_iteration">[docs]</a>
    <span class="n">num_raft_iteration</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;number of iterations of the raft aligner.&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="RaftAlignerArguments.raft_batch_size">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.RaftAlignerArguments.raft_batch_size">[docs]</a>
    <span class="n">raft_batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;only select </span><span class="si">{raft_batch_size}</span><span class="s2"> samples each time for STF training.&quot;</span><span class="p">)},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="RaftAlignerArguments.top_reward_percentage">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.RaftAlignerArguments.top_reward_percentage">[docs]</a>
    <span class="n">top_reward_percentage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;only top </span><span class="si">{top_reward_percentage}</span><span class="s2"> samples in the raft batch,&quot;</span>
                <span class="s2">&quot; (in terms of rewards), will be used for SFT the model.&quot;</span>
            <span class="p">),</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="RaftAlignerArguments.inference_batch_size_per_device">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.RaftAlignerArguments.inference_batch_size_per_device">[docs]</a>
    <span class="n">inference_batch_size_per_device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;every device will infer </span><span class="si">{inference_batch_size_per_device}</span><span class="s2">&quot;</span>
                <span class="s2">&quot; samples in parallel. The inferred results will be concatenaed&quot;</span>
                <span class="s2">&quot; with inputs and attach a reward.&quot;</span>
            <span class="p">),</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="RaftAlignerArguments.collection_strategy">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.RaftAlignerArguments.collection_strategy">[docs]</a>
    <span class="n">collection_strategy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;top&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;</span><span class="si">{collection_strategy}</span><span class="s2"> is either top or local&quot;</span>
                <span class="s2">&quot; top means that we rank the samples globally regardless of the prompts&quot;</span>
                <span class="s2">&quot; local means that we only rank the samples with the same prompt&quot;</span>
            <span class="p">),</span>
        <span class="p">},</span>
    <span class="p">)</span></div>
</div>



<span class="nd">@dataclass</span>
<div class="viewcode-block" id="BenchmarkingArguments">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.BenchmarkingArguments">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">BenchmarkingArguments</span><span class="p">:</span>
<div class="viewcode-block" id="BenchmarkingArguments.dataset_name">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.BenchmarkingArguments.dataset_name">[docs]</a>
    <span class="n">dataset_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;benchmark dataset name provided by lmflow&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="BenchmarkingArguments.lm_evaluation_metric">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.BenchmarkingArguments.lm_evaluation_metric">[docs]</a>
    <span class="n">lm_evaluation_metric</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the metric the model will be evaluated on&quot;</span><span class="p">,</span>
            <span class="s2">&quot;choices&quot;</span><span class="p">:</span> <span class="p">[</span>
                <span class="s2">&quot;acc&quot;</span><span class="p">,</span>
                <span class="s2">&quot;acc_norm&quot;</span><span class="p">,</span>
                <span class="s2">&quot;bleu&quot;</span><span class="p">,</span>
                <span class="s2">&quot;chrf&quot;</span><span class="p">,</span>
                <span class="s2">&quot;em&quot;</span><span class="p">,</span>
                <span class="s2">&quot;f1&quot;</span><span class="p">,</span>
                <span class="s2">&quot;ppl&quot;</span><span class="p">,</span>
                <span class="s2">&quot;ter&quot;</span><span class="p">,</span>
                <span class="s2">&quot;r@1&quot;</span><span class="p">,</span>
                <span class="s2">&quot;r@2&quot;</span><span class="p">,</span>
                <span class="s2">&quot;mrr&quot;</span><span class="p">,</span>
                <span class="s2">&quot;mc1&quot;</span><span class="p">,</span>
                <span class="s2">&quot;mc2&quot;</span><span class="p">,</span>
                <span class="s2">&quot;word_perplexity&quot;</span><span class="p">,</span>
                <span class="s2">&quot;byte_perplexity&quot;</span><span class="p">,</span>
                <span class="s2">&quot;bits_per_byte&quot;</span><span class="p">,</span>
            <span class="p">],</span>
        <span class="p">},</span>
    <span class="p">)</span></div>
</div>



<span class="nd">@dataclass</span>
<div class="viewcode-block" id="DPOAlignerArguments">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOAlignerArguments">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">DPOAlignerArguments</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The arguments for the DPO training script.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="DPOAlignerArguments.local_rank">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOAlignerArguments.local_rank">[docs]</a>
    <span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;For distributed training: local_rank&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

    <span class="c1"># data parameters</span>
<div class="viewcode-block" id="DPOAlignerArguments.beta">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOAlignerArguments.beta">[docs]</a>
    <span class="n">beta</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the beta parameter for DPO loss&quot;</span><span class="p">})</span></div>

    <span class="c1"># # training parameters</span>
<div class="viewcode-block" id="DPOAlignerArguments.learning_rate">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOAlignerArguments.learning_rate">[docs]</a>
    <span class="n">learning_rate</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;optimizer learning rate&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="DPOAlignerArguments.lr_scheduler_type">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOAlignerArguments.lr_scheduler_type">[docs]</a>
    <span class="n">lr_scheduler_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the lr scheduler type&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="DPOAlignerArguments.warmup_steps">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOAlignerArguments.warmup_steps">[docs]</a>
    <span class="n">warmup_steps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the number of warmup steps&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="DPOAlignerArguments.weight_decay">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOAlignerArguments.weight_decay">[docs]</a>
    <span class="n">weight_decay</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the weight decay&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="DPOAlignerArguments.optimizer_type">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOAlignerArguments.optimizer_type">[docs]</a>
    <span class="n">optimizer_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="s2">&quot;paged_adamw_32bit&quot;</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the optimizer type&quot;</span><span class="p">})</span></div>


<div class="viewcode-block" id="DPOAlignerArguments.per_device_train_batch_size">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOAlignerArguments.per_device_train_batch_size">[docs]</a>
    <span class="n">per_device_train_batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;train batch size per device&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="DPOAlignerArguments.per_device_eval_batch_size">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOAlignerArguments.per_device_eval_batch_size">[docs]</a>
    <span class="n">per_device_eval_batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;eval batch size per device&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="DPOAlignerArguments.gradient_accumulation_steps">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOAlignerArguments.gradient_accumulation_steps">[docs]</a>
    <span class="n">gradient_accumulation_steps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the number of gradient accumulation steps&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="DPOAlignerArguments.gradient_checkpointing">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOAlignerArguments.gradient_checkpointing">[docs]</a>
    <span class="n">gradient_checkpointing</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;whether to use gradient checkpointing&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="DPOAlignerArguments.gradient_checkpointing_use_reentrant">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOAlignerArguments.gradient_checkpointing_use_reentrant">[docs]</a>
    <span class="n">gradient_checkpointing_use_reentrant</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;whether to use reentrant for gradient checkpointing&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="DPOAlignerArguments.max_prompt_length">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOAlignerArguments.max_prompt_length">[docs]</a>
    <span class="n">max_prompt_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the maximum prompt length&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="DPOAlignerArguments.max_length">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOAlignerArguments.max_length">[docs]</a>
    <span class="n">max_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the maximum sequence length&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="DPOAlignerArguments.max_steps">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOAlignerArguments.max_steps">[docs]</a>
    <span class="n">max_steps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;max number of training steps&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="DPOAlignerArguments.logging_steps">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOAlignerArguments.logging_steps">[docs]</a>
    <span class="n">logging_steps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the logging frequency&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="DPOAlignerArguments.save_steps">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOAlignerArguments.save_steps">[docs]</a>
    <span class="n">save_steps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the saving frequency&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="DPOAlignerArguments.eval_steps">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOAlignerArguments.eval_steps">[docs]</a>
    <span class="n">eval_steps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the evaluation frequency&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="DPOAlignerArguments.output_dir">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOAlignerArguments.output_dir">[docs]</a>
    <span class="n">output_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;./results&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the output directory&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="DPOAlignerArguments.log_freq">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOAlignerArguments.log_freq">[docs]</a>
    <span class="n">log_freq</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the logging frequency&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="DPOAlignerArguments.sanity_check">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOAlignerArguments.sanity_check">[docs]</a>
    <span class="n">sanity_check</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;only train on 1000 samples&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="DPOAlignerArguments.report_to">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOAlignerArguments.report_to">[docs]</a>
    <span class="n">report_to</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;wandb&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s1">&#39;The list of integrations to report the results and logs to. Supported platforms are `&quot;azure_ml&quot;`,&#39;</span>
            <span class="s1">&#39;`&quot;comet_ml&quot;`, `&quot;mlflow&quot;`, `&quot;neptune&quot;`, `&quot;tensorboard&quot;`,`&quot;clearml&quot;` and `&quot;wandb&quot;`. &#39;</span>
            <span class="s1">&#39;Use `&quot;all&quot;` to report to all integrations installed, `&quot;none&quot;` for no integrations.&#39;</span>
        <span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="DPOAlignerArguments.seed">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOAlignerArguments.seed">[docs]</a>
    <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Random seed that will be set at the beginning of training.&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="DPOAlignerArguments.run_name">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOAlignerArguments.run_name">[docs]</a>
    <span class="n">run_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="s2">&quot;dpo&quot;</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The name of the run.&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="DPOAlignerArguments.eval_dataset_path">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOAlignerArguments.eval_dataset_path">[docs]</a>
    <span class="n">eval_dataset_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The path of the eval dataset.&quot;</span><span class="p">})</span></div>
</div>



<span class="nd">@dataclass</span>
<div class="viewcode-block" id="DPOv2AlignerArguments">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOv2AlignerArguments">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">DPOv2AlignerArguments</span><span class="p">(</span><span class="n">FinetunerArguments</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The arguments for the DPOv2 training script.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># general args</span>
<div class="viewcode-block" id="DPOv2AlignerArguments.random_seed">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOv2AlignerArguments.random_seed">[docs]</a>
    <span class="n">random_seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the random seed&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="DPOv2AlignerArguments.accelerate_config_file">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOv2AlignerArguments.accelerate_config_file">[docs]</a>
    <span class="n">accelerate_config_file</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;file path for accelerate config file, only used in memory safe dpov2 align.&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

    <span class="c1"># pair sampling args</span>
<div class="viewcode-block" id="DPOv2AlignerArguments.margin_scale">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOv2AlignerArguments.margin_scale">[docs]</a>
    <span class="n">margin_scale</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the margin scale&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="DPOv2AlignerArguments.sampling_paired_method">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOv2AlignerArguments.sampling_paired_method">[docs]</a>
    <span class="n">sampling_paired_method</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="s2">&quot;max_random&quot;</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the choose type&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="DPOv2AlignerArguments.length_penalty">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOv2AlignerArguments.length_penalty">[docs]</a>
    <span class="n">length_penalty</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the length penalty&quot;</span><span class="p">})</span></div>

    <span class="c1"># data collator args</span>
<div class="viewcode-block" id="DPOv2AlignerArguments.max_length">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOv2AlignerArguments.max_length">[docs]</a>
    <span class="n">max_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the maximum sequence length, prompt + output&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="DPOv2AlignerArguments.max_prompt_length">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOv2AlignerArguments.max_prompt_length">[docs]</a>
    <span class="n">max_prompt_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the maximum prompt length&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="DPOv2AlignerArguments.mask_prompt">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOv2AlignerArguments.mask_prompt">[docs]</a>
    <span class="n">mask_prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;mask prompt&quot;</span><span class="p">})</span></div>

    <span class="c1"># dpov2 aligner args</span>
<div class="viewcode-block" id="DPOv2AlignerArguments.beta">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOv2AlignerArguments.beta">[docs]</a>
    <span class="n">beta</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the beta parameter for DPO loss&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="DPOv2AlignerArguments.loss_type">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.DPOv2AlignerArguments.loss_type">[docs]</a>
    <span class="n">loss_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;the loss type&quot;</span><span class="p">})</span></div>
</div>



<span class="nd">@dataclass</span>
<div class="viewcode-block" id="IterativeAlignerArguments">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.IterativeAlignerArguments">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">IterativeAlignerArguments</span><span class="p">(</span><span class="n">InferencerArguments</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Arguments for iterative aligners.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="IterativeAlignerArguments.dataset_path_list">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.IterativeAlignerArguments.dataset_path_list">[docs]</a>
    <span class="n">dataset_path_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default_factory</span><span class="o">=</span><span class="nb">list</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The list of dataset paths for iterative aligners.&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="IterativeAlignerArguments.initial_iter_idx">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.IterativeAlignerArguments.initial_iter_idx">[docs]</a>
    <span class="n">initial_iter_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The initial iteration index, 0 refers to the first dataset in dataset_path_list.&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>
</div>



<span class="nd">@dataclass</span>
<div class="viewcode-block" id="IterativeDPOAlignerArguments">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.IterativeDPOAlignerArguments">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">IterativeDPOAlignerArguments</span><span class="p">(</span><span class="n">IterativeAlignerArguments</span><span class="p">,</span> <span class="n">DPOv2AlignerArguments</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Arguments for iterative DPO aligners.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="IterativeDPOAlignerArguments.output_dir">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.IterativeDPOAlignerArguments.output_dir">[docs]</a>
    <span class="n">output_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;./runs&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Output path for the inferenced results&quot;</span><span class="p">},</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="IterativeDPOAlignerArguments.reward_model_inference_batch_size">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.IterativeDPOAlignerArguments.reward_model_inference_batch_size">[docs]</a>
    <span class="n">reward_model_inference_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The batch size for reward model inference.&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="IterativeDPOAlignerArguments.reward_model_inference_block_size">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.IterativeDPOAlignerArguments.reward_model_inference_block_size">[docs]</a>
    <span class="n">reward_model_inference_block_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The block size for reward model inference.&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="IterativeDPOAlignerArguments.do_response_generation">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.IterativeDPOAlignerArguments.do_response_generation">[docs]</a>
    <span class="n">do_response_generation</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to generate responses using the model.&quot;</span><span class="p">}</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="IterativeDPOAlignerArguments.do_scoring">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.IterativeDPOAlignerArguments.do_scoring">[docs]</a>
    <span class="n">do_scoring</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to score the responses using the reward model.&quot;</span><span class="p">})</span></div>

<div class="viewcode-block" id="IterativeDPOAlignerArguments.do_dpo_align">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.IterativeDPOAlignerArguments.do_dpo_align">[docs]</a>
    <span class="n">do_dpo_align</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to perform DPO alignment.&quot;</span><span class="p">})</span></div>
</div>



<div class="viewcode-block" id="PIPELINE_ARGUMENT_MAPPING">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.PIPELINE_ARGUMENT_MAPPING">[docs]</a>
<span class="n">PIPELINE_ARGUMENT_MAPPING</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;finetuner&quot;</span><span class="p">:</span> <span class="n">FinetunerArguments</span><span class="p">,</span>
    <span class="s2">&quot;evaluator&quot;</span><span class="p">:</span> <span class="n">EvaluatorArguments</span><span class="p">,</span>
    <span class="s2">&quot;inferencer&quot;</span><span class="p">:</span> <span class="n">InferencerArguments</span><span class="p">,</span>
    <span class="s2">&quot;vllm_inferencer&quot;</span><span class="p">:</span> <span class="n">InferencerArguments</span><span class="p">,</span>
    <span class="s2">&quot;sglang_inferencer&quot;</span><span class="p">:</span> <span class="n">InferencerArguments</span><span class="p">,</span>
    <span class="s2">&quot;rm_inferencer&quot;</span><span class="p">:</span> <span class="n">InferencerArguments</span><span class="p">,</span>
    <span class="s2">&quot;raft_aligner&quot;</span><span class="p">:</span> <span class="n">RaftAlignerArguments</span><span class="p">,</span>
    <span class="s2">&quot;dpo_aligner&quot;</span><span class="p">:</span> <span class="n">DPOAlignerArguments</span><span class="p">,</span>
    <span class="s2">&quot;rm_tuner&quot;</span><span class="p">:</span> <span class="n">RewardModelTunerArguments</span><span class="p">,</span>
    <span class="s2">&quot;dpov2_aligner&quot;</span><span class="p">:</span> <span class="n">DPOv2AlignerArguments</span><span class="p">,</span>
    <span class="s2">&quot;iterative_dpo_aligner&quot;</span><span class="p">:</span> <span class="n">IterativeDPOAlignerArguments</span><span class="p">,</span>
<span class="p">}</span></div>



<div class="viewcode-block" id="AutoArguments">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.AutoArguments">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">AutoArguments</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Automatically choose arguments from FinetunerArguments or EvaluatorArguments.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="AutoArguments.get_pipeline_args_class">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.AutoArguments.get_pipeline_args_class">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_pipeline_args_class</span><span class="p">(</span><span class="n">pipeline_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">PIPELINE_ARGUMENT_MAPPING</span><span class="p">[</span><span class="n">pipeline_name</span><span class="p">]</span></div>
</div>



<div class="viewcode-block" id="split_args">
<a class="viewcode-back" href="../../autoapi/lmflow/args/index.html#lmflow.args.split_args">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">split_args</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">elem</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">)]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">args</span></div>

</pre></div>

                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
       Copyright LMFlow 2025.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.2.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>